{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylidc as pl\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [15:48<00:00,  4.74s/it]\n"
     ]
    }
   ],
   "source": [
    "# start, stop, id\n",
    "part = (500,700,3)\n",
    "X = []\n",
    "Y = []\n",
    "for scan in tqdm(pl.query(pl.Scan).filter(pl.Scan.id >= part[0], pl.Scan.id < part[1]).all()):\n",
    "    vol = scan.to_volume(verbose=False)\n",
    "    slices = [x.bbox()[2] for x in scan.annotations]\n",
    "    indexes = [list(range(slice.start, slice.stop)) for slice in slices]\n",
    "    #flatten\n",
    "    indexes = np.unique([index for l in indexes for index in l])\n",
    "    mask = np.zeros(vol.shape)\n",
    "    for ann in scan.annotations:\n",
    "        mask[ann.bbox()] += ann.boolean_mask()\n",
    "    mask = mask > 0\n",
    "    for z in indexes:\n",
    "        cmsk = np.zeros((mask.shape[0], mask.shape[1], 2), dtype='bool')\n",
    "        cmsk[:,:, 0] = mask[:,:,z]\n",
    "        cmsk[:,:, 1] = np.logical_not(mask[:,:,z])\n",
    "        X.append(vol[:,:,z])\n",
    "        Y.append(cmsk)\n",
    "partdb = {'X': X, 'Y': Y}\n",
    "np.savez_compressed('lidc-small-part' + str(part[2]), db=partdb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [17:43<00:00,  3.56s/it]\n"
     ]
    }
   ],
   "source": [
    "# start, stop, id\n",
    "part = (0,300,1)\n",
    "X = []\n",
    "Y = []\n",
    "for scan in tqdm(pl.query(pl.Scan).filter(pl.Scan.id >= part[0], pl.Scan.id < part[1]).all()):\n",
    "    vol = scan.to_volume(verbose=False)\n",
    "    slices = [x.bbox()[2] for x in scan.annotations]\n",
    "    indexes = [list(range(slice.start, slice.stop)) for slice in slices]\n",
    "    #flatten\n",
    "    indexes = np.unique([index for l in indexes for index in l])\n",
    "    for ann in scan.annotations:\n",
    "        mask = ann.boolean_mask() > 0\n",
    "        for z in range(mask.shape[2]):\n",
    "            cmsk = np.zeros((mask.shape[0], mask.shape[1], 2), dtype='bool')\n",
    "            cmsk[:,:, 0] = mask[:,:,z]\n",
    "            cmsk[:,:, 1] = np.logical_not(mask[:,:,z])\n",
    "            X.append(vol[ann.bbox()][:,:,z])\n",
    "            Y.append(cmsk)\n",
    "partdb = {'X': X, 'Y': Y}\n",
    "np.savez_compressed('lidc-small-part' + str(part[2]), db=partdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.19it/s]\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "for i in tqdm(range(1,3)):\n",
    "    db = np.load('lidc-small-part' + str(i) + '.npz', allow_pickle=True)['db'][()]\n",
    "    X = X + db['X']\n",
    "    Y = Y + db['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X)):\n",
    "    new_shape_x = slice(0, (X[i].shape[0] // 3) * 3)\n",
    "    new_shape_y = slice(0, (X[i].shape[1] // 3) * 3)\n",
    "    X[i] = X[i][new_shape_x, new_shape_y]\n",
    "    Y[i] = Y[i][new_shape_x, new_shape_y, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving training set ...\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.permutation(len(X))\n",
    "X = [X[i] for i in idx]\n",
    "Y = [Y[i] for i in idx]\n",
    "print('Saving training set ...')\n",
    "traindb = {'X': X, 'Y': Y}\n",
    "np.savez_compressed('lidc-small-train', db=traindb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:18<00:00, 18.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving validation set ...\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "for i in tqdm(range(3,4)):\n",
    "    db = np.load('lidc-small-part' + str(i) + '.npz', allow_pickle=True)['db'][()]\n",
    "    X = X + db['X']\n",
    "    Y = Y + db['Y']\n",
    "idx = np.random.permutation(len(X))\n",
    "X = [X[i] for i in idx]\n",
    "Y = [Y[i] for i in idx]\n",
    "print('Saving validation set ...')\n",
    "traindb = {'X': X, 'Y': Y}\n",
    "np.savez_compressed('lidc-small-val', db=traindb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_masks = np.array(traindb.get('Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11708, 512, 512, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.59386779e-04, 9.99340613e-01])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = np.mean(all_masks, axis=(0,1,2))\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.58280294e+02, 5.00329911e-01])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.median(freq)/freq\n",
    "weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
