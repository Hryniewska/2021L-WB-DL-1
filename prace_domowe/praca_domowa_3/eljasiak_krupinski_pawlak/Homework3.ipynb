{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "unlimited-pacific",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sticky-refrigerator",
   "metadata": {},
   "source": [
    "## 1. Preprocessing in ERSCovid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arctic-concord",
   "metadata": {},
   "source": [
    "Authors of the ERSCovid NN have used other NN, \"DenseNet121-FPN\", to perform data preprocessing. It segments original chest CT scan images into lung area mask. They have used other means, like \"cubic bounding box\" and \"Non-lung area suppression\" to further increase accuracy of segmentation. Finally, the images are normalized and resized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-manual",
   "metadata": {},
   "source": [
    "### First part of preprocessing\n",
    "\n",
    "\"\n",
    "\n",
    "Automatic lung segmentation\n",
    "\n",
    "Routinely used chest CT image includes some non-lung areas (muscle, heart, et al.) and blank space outside body. To focus on analyzing lung area, we used a fully automatic DL model (DenseNet121-FPN) to segment lung areas in chest CT image. This model is pre-trained using 1.4 million natural images, and fine-tuned on VESSEL12 dataset (supplementary methods S4).\n",
    "\n",
    "Through this automatic lung segmentation procedure, we acquired the lung mask in CT image.\n",
    "\n",
    "\"\n",
    "\n",
    "--- <cite>1-8, page 9</cite>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-bouquet",
   "metadata": {},
   "source": [
    "### Description\n",
    "\n",
    "It is the first step towards creating lung masks. The DL model finds only lung area and marks it.\n",
    "\n",
    "\n",
    "<cite>\"DenseNet is a network architecture where each layer is directly connected to every other layer in a feed-forward fashion (within each dense block). For each layer, the feature maps of all preceding layers are treated as separate inputs whereas its own feature maps are passed on as inputs to all subsequent layers.\"</cite>\n",
    "\n",
    "--- DenseNet documentation\n",
    "\n",
    "Link to the DenseNet network architecture: https://github.com/liuzhuang13/DenseNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-freight",
   "metadata": {},
   "source": [
    "### Code fragments\n",
    "\n",
    "The code itself is too long to include it in this file, as it is about 100 lines long (it is a neural network after all). However, the code resides inside \"lungSegNet4seg19Conv.py\" file in <strong>SegLung class</strong>, between 24 and 122 file lines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-killing",
   "metadata": {},
   "source": [
    "### Second part of preprocessing\n",
    "\n",
    "\"\n",
    "\n",
    "However, some inflammatory tissues attaching to lung wall may be excluded falsely by the DenseNet121-FPN model. To increase the robustness of the DL system, we used the cubic bounding box of the segmented lung mask to crop lung areas in CT image, and defined this cubic lung area as lung-ROI. In this lung-ROI, all inflammatory tissues and the whole lung were correctly reserved, and most areas outside of lung were eliminated.\n",
    "\n",
    "\"\n",
    "\n",
    "--- <cite>8-13, page 9</cite>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-blocking",
   "metadata": {},
   "source": [
    "### Description\n",
    "\n",
    "To increase the accuracy of the model and to reduce the size of datasets, authors crop chest CT scan images to remove unnecessary background with the mothod called \"cubic bounding box\". Basically, it crops the image to the smallest square, which does not exclude any lung mask."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-parent",
   "metadata": {},
   "source": [
    "### Code fragments\n",
    "\n",
    "Once again, the code is rather long. Main part is between 128 and 229 lines in the same file. The code is inside <strong>extractLungArea function</strong>. Also, there is a short code fragment used in that function (261-271 lines):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-awareness",
   "metadata": {},
   "source": [
    "```python\n",
    "def _boundingBox(self, A):\n",
    "    B = np.argwhere(A)\n",
    "    if A.ndim == 3:\n",
    "        (zstart, ystart, xstart), (zstop, ystop, xstop) = B.min(axis=0), B.max(axis=0) + 1\n",
    "        return (zstart, ystart, xstart), (zstop, ystop, xstop)\n",
    "    elif A.ndim == 2:\n",
    "        (ystart, xstart), (ystop, xstop) = B.min(axis=0), B.max(axis=0) + 1\n",
    "        return (ystart, xstart), (ystop, xstop)\n",
    "    else:\n",
    "        print('box err')\n",
    "        return\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scientific-playlist",
   "metadata": {},
   "source": [
    "### Third part of preprocessing\n",
    "\n",
    "\"\n",
    "\n",
    "Non-long area suppression\n",
    "\n",
    "After the above processing, some non-lung tissues or organs (e.g., spine, heart) inside the lung-ROI may also exists. Consequently, we proposed a non-lung area suppression operation to suppress the intensities of non-lung areas inside the lung-ROI (supplementary methods S4). Finally, the lung-ROI is standardized by z-score normalization, and resized to the size of 48×240×360 for further process.\n",
    "\n",
    "\"\n",
    "\n",
    "--- <cite>14-19, page 9</cite>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-framework",
   "metadata": {},
   "source": [
    "### Description\n",
    "\n",
    "It supresses the non-lung areas, which were caught in the first step by the lung area masks. The consequence is removed redundant mask area. Then it is z-score normalized. At last it is resized to 48x240x360 and saved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-printer",
   "metadata": {},
   "source": [
    "### Code fragments\n",
    "\n",
    "Code is nicely marked between two comment lines, 230. and 248. The code is inside <strong>extractLungArea function</strong>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-medicaid",
   "metadata": {},
   "source": [
    "```python\n",
    "    if dotMask == True:\n",
    "        maskUse = mask[zstartUse:zstopUse]\n",
    "        maskUse = zoom(maskUse.astype(np.float32), (1, MASKSCALE[0], MASKSCALE[1]), order=1)\n",
    "        maskUse = maskUse[:, ystart:ystop, xstart:xstop]\n",
    "\n",
    "        full95 = np.percentile(lungUse, 95)\n",
    "        lungUse[lungUse>full95] = full95\n",
    "        lungarray = lungUse.copy()\n",
    "        lungarray[maskUse<0.2] = 0\n",
    "        lungarea = lungUse[maskUse>0.2]\n",
    "        wallarray = lungUse.copy()\n",
    "        lmean, lstd = lungarea.mean(), lungarea.std()\n",
    "        #print('lmean', lmean-3*lstd, lmean+3*lstd)\n",
    "\n",
    "        wallarray = np.clip(wallarray, lmean-4*lstd, lmean+4*lstd)\n",
    "        wallarray[maskUse>0.2] = 0\n",
    "        lungUse = lungarray + wallarray\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inappropriate-thinking",
   "metadata": {},
   "source": [
    "## 2. Upgrades to preprocessing in ERSCovid\n",
    "\n",
    "### 2.1 Fourier transform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banner-taylor",
   "metadata": {},
   "source": [
    "Our data is by defult heavly preprocessed in order to be used by the model, but we were able to slightly improve it's performance by applying Fourier transformation. From:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-appraisal",
   "metadata": {},
   "source": [
    "`accuracy: 0.6512`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flush-shannon",
   "metadata": {},
   "source": [
    "To:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-seeking",
   "metadata": {},
   "source": [
    "`accuracy: 0.6860` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arranged-switch",
   "metadata": {},
   "source": [
    "The question still stands could we create better mask by applying FFT to raw data. We are unable to test it now due to long process of creating such masks. But we plan to do it before next turnover "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-migration",
   "metadata": {},
   "source": [
    "## 3. Signs recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-patent",
   "metadata": {},
   "source": [
    "### 3.1. First Article\n",
    "\n",
    "* Resizing images from  GTSRB (German Traffic Sign Benchmarks) dataset to resolution of 32 x 32 pixels. \n",
    "* Dividing dataset into three subsets for training preserving the proportions of the images for every class.\n",
    "* Normalization of images was performed by dividing them by 255 and subtracting the mean image, which, in turn, was calculated from the training dataset.\n",
    "* Preparing dataset containing 3-channelled RGB images\n",
    "\n",
    "Source:\n",
    "Sichkar V.N., Kolyubin S.A. Effect of various dimension convolutional layer filters on traffic sign classification accuracy. Scientific and Technical Journal of Information Technologies, Mechanics and Optics, 2019, vol. 19, no. 3, pp. 546–552 (in English). doi: 10.17586/2226-1494-2019-19-3-546-552 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-artwork",
   "metadata": {},
   "source": [
    "### 3.2. Second Article\n",
    "* Converting 3 channel image to a single grayscale image.\n",
    "* Centering the distribution of the image dataset by subtracting each image by the dataset mean and divide by its standard deviation. This helps the model treating images uniformly.\n",
    "\n",
    "Source: https://towardsdatascience.com/recognizing-traffic-signs-with-over-98-accuracy-using-deep-learning-86737aedc2ab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-feedback",
   "metadata": {},
   "source": [
    "### 3.3 Third Article\n",
    "* Adjusting the image size\n",
    "* Enhancing the contrast of the image by transforming the values obtained in the intensity image.\n",
    "* Transforming the input picture into a gray scale picture.\n",
    "* Detecting edges in the image using the Laplacian of Gaussian (LOG). The function is centered on zero and with standard deviation σ.\n",
    "* Eliminating areas of the picture that exceed a certain size. \n",
    "* Calculating and normalizing the signature of every ROI.\n",
    "* Calculating the contour of every ROI, its centroid and the closest point to the upper right corner of the image.\n",
    "* Obtaining the signature by calculating the distance between the centroid and perimeter.\n",
    "* Normalizing the signature to fit its value between 0 and 1.\n",
    "\n",
    "Source: https://www.sciencedirect.com/science/article/pii/S1474667016416009"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-district",
   "metadata": {},
   "source": [
    "## 4. Denoising and debluring images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concerned-burst",
   "metadata": {},
   "source": [
    "### 4.1 Noise models\n",
    "Noise has many origins, and even though that It may look similar, slight differneces can mean that one method will work and the other won't. Before we look at techniques of removing noise let's look what it is.\n",
    "\n",
    "- **Additive noise**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "another-spectacular",
   "metadata": {},
   "source": [
    "![](https://latex.codecogs.com/svg.latex?Y(x,y)%20=%20X(x,y)%20+%20N(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-lesson",
   "metadata": {},
   "source": [
    "- **Multiplicative noise**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tribal-battery",
   "metadata": {},
   "source": [
    "![](https://latex.codecogs.com/svg.latex?Y(x,y)%20=%20X(x,y)%20*%20N(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "false-sleeping",
   "metadata": {},
   "source": [
    "### 4.2 Noise types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-cargo",
   "metadata": {},
   "source": [
    "#### Gaussian noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-compiler",
   "metadata": {},
   "source": [
    "![](https://iq.opengenus.org/content/images/2019/06/Untitled-Diagram--10-.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-parks",
   "metadata": {},
   "source": [
    "#### Salt and pepper noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-mitchell",
   "metadata": {},
   "source": [
    "![](https://www.researchgate.net/profile/Jayanthi-Sivaswamy-2/publication/224373547/figure/fig2/AS:302679118106633@1449175734017/Grey-scale-image-corrupted-with-salt-and-pepper-noise-which-is-used-for-training-the-HNN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-botswana",
   "metadata": {},
   "source": [
    "<img src=\"https://raspository.com/wp-content/uploads/2019/04/owlsaltpepper-1024x684.jpg\" alt=\"drawing\" height=\"300\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-physics",
   "metadata": {},
   "source": [
    "#### Poisson/Short Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-indonesia",
   "metadata": {},
   "source": [
    "<img src=\"https://www.researchgate.net/publication/324113269/figure/fig6/AS:620818899943430@1525026168750/Denoising-experiments-for-Poisson-Gaussian-corrupted-image-a-image-with.png\" alt=\"drawing\" width=\"500\" height=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-antarctica",
   "metadata": {},
   "source": [
    "<img src=\"https://www.researchgate.net/publication/324113269/figure/fig5/AS:620818899927046@1525026168589/Noise-analysis-of-Poisson-noise-a-Poisson-noise-added-image-b-noiseless-image.png\" alt=\"drawing\" width=\"500\" height=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "democratic-granny",
   "metadata": {},
   "source": [
    "### 4.3 Denoising techniques\n",
    "There is a bunch of denoising techniques statring from simple spartial ones, that use nieghboring values to correct one suspicious. Other focus on gradient of the image, other use Transforms like Wavelet Transform. And meny state-of-the-art techniques weren't mentioned on the image below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-princeton",
   "metadata": {},
   "source": [
    "<img src=\"https://iq.opengenus.org/content/images/2019/07/Untitled-Diagram--19-.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-aviation",
   "metadata": {},
   "source": [
    "#### Spartial domain filters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-paraguay",
   "metadata": {},
   "source": [
    "If spartial domain filter we will look at nerby pixels to determin the \"correct\" value of one. Often kernel is used, and it  determines the type of filter we will use. For mean filter this could be the 3x3 matrix of ones. If we use this kernel on image and devide value of every filter by 9 we get image of mean values, and that's it. Of course we can use different kernels or non linear solution, e.q. median of values in given kernel. Those approaches are simple, rather fast and solve simple problems, but have very obvious downsides. Example will be shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-forwarding",
   "metadata": {},
   "source": [
    "#### CNN approach\n",
    "\"\"\"\n",
    "\n",
    "The state-of-the-art deep learning denoising methods are typically based on CNNs. The general model for deep learning-based denoising methods is formulated as\n",
    "![](https://latex.codecogs.com/svg.latex?\\underset{\\Theta}{\\min%20}%20loss\\left(\\hat{x},x\\right),s.t.\\hat{x}=F\\left(y,\\sigma;%20\\Theta%20\\right))\n",
    "\n",
    "where F(⋅) denotes a CNN with parameter set Θ, and loss(⋅) denotes the loss function. loss(⋅) is used to estimate the proximity between the denoised image x^ and the ground-truth x. Owing to their outstanding denoising ability, considerable attention has been focused on deep learning-based denoising methods.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Fan, L., Zhang, F., Fan, H. et al. Brief review of image denoising techniques. Vis. Comput. Ind. Biomed. Art 2, 7 (2019). https://doi.org/10.1186/s42492-019-0016-7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-manual",
   "metadata": {},
   "source": [
    "### Results of diffrent approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-stand",
   "metadata": {},
   "source": [
    "**classical approaches**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finnish-classroom",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/max/1091/1*QSedlO9j_1h24bLuwSVV_g.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romance-degree",
   "metadata": {},
   "source": [
    "**different CNNs**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-repair",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/max/1091/1*uN9K233bahkih5C9alaJIg.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-accreditation",
   "metadata": {},
   "source": [
    "We shouldn't be suprised but evry CNN outperformed classical approaches. The difference is huge. One of the hardest thing to get right are the edges, many techniques has problem with keeping them sharp, and those that do performe worse in the other parts of the image. CNNs can perform well in both cases that's why they are so efficient in this task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-alloy",
   "metadata": {},
   "source": [
    "### 4.4 Blur\n",
    "\n",
    "#### Blur models\n",
    "Mathematical formautaltion of blur is not that diffferent than noise, but the origin of blur is completly different. It's worth mentioning that some debluring techniques work well on denoising problems, but usually those problems are solved seperately"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-stations",
   "metadata": {},
   "source": [
    "![](https://latex.codecogs.com/svg.latex?Y(x,y)%20=%20X(x,y)%20\\otimes%20h(x,y)+%20n(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-sterling",
   "metadata": {},
   "source": [
    "#### A) Motion blur          \n",
    "#### B) Linear motion blur                  \n",
    "#### C) Defocus blur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-threat",
   "metadata": {},
   "source": [
    "![](https://storage.googleapis.com/plos-corpus-prod/10.1371/journal.pone.0230619/1/pone.0230619.g002.PNG_M?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=wombat-sa%40plos-prod.iam.gserviceaccount.com%2F20210401%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20210401T074037Z&X-Goog-Expires=3600&X-Goog-SignedHeaders=host&X-Goog-Signature=31e6bff18c0601dd12460adbff9673ff491bf800491b2bc2cea202571772db220edc6d430c1c90b599d3de4f5160bf3b9e4d7dcfd3401dafeb242dda75f5b38ca177070df04b1f87f3de15ad20d571d53228ac3df90fe9b45771522def3047c0448dbbc17f2354df4e713e4c25cb66308e70f6a8d09086fb35b8c8334f66ff1a1e25a1ac5ee5173081f1129f4b386dedf0f7c24e2179a16e50b19994c42f490b4a4ff9c7f8b3bce0dd10d30c82ce1746832883eaa4e75a94b3a2739af1938b31be38aa4c2988f3f24560945ff52bc9d6120691f4e45fafb527d1545e6d5aa521b69ea4f19c2f6c80a548abb47455c4f5a0d8b3f9b8117ea5248f56d9fef23e10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-basement",
   "metadata": {},
   "source": [
    "#### Motion blur\n",
    "Left column shows image, second one edges, and the last one blur feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrow-softball",
   "metadata": {},
   "source": [
    "![](https://storage.googleapis.com/plos-corpus-prod/10.1371/journal.pone.0230619/1/pone.0230619.g004.PNG_M?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=wombat-sa%40plos-prod.iam.gserviceaccount.com%2F20210401%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20210401T074152Z&X-Goog-Expires=3600&X-Goog-SignedHeaders=host&X-Goog-Signature=4fdc493f14ad6c1962b0c71fdcb5fee7a6af596061a148891474f46691c150852a9c691c3fbab62fdf24ad8000d74b899d06ec460d2be453c9c9c93e7633bfa1c1264a189337ec716a6dce17f786d291382e3c75d18671263d5d656aafa1735a5366fb9865e163a57cbccad0379f0356a58a46f89d35164e1a4a47a2d257f624539a0fe801898252622fdd206bdc3a98b3ebbf413ab62591c00bd535b7cce7688e4af704df57e75e9856f190b46f99f895f59b421f8d8e49e3e650e623b6e695d68584cb95e9f66847dc8bd269e1f54b3a423b1d12d66453f2c9b5ed6dadbee7908dd6b90a08df8615751e8672e5ab2cb2458a5902c31154cf7aa4a565ed2d16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-indonesia",
   "metadata": {},
   "source": [
    "#### Defocus blur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-credits",
   "metadata": {},
   "source": [
    "![](https://storage.googleapis.com/plos-corpus-prod/10.1371/journal.pone.0230619/1/pone.0230619.g003.PNG_M?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=wombat-sa%40plos-prod.iam.gserviceaccount.com%2F20210401%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20210401T074157Z&X-Goog-Expires=3600&X-Goog-SignedHeaders=host&X-Goog-Signature=0496bd4d895b6d34ec4ab8df2a838b247109cb1a75979bf28f4873963816e3b751098d433d50c43efae74c97adad109d525d45fb37afe2843c751de8189f748a5c0d948ff791254450e41c69bb290cb83cf7db5bef259e85e102b23dd1c920e5031c49af09451daa1d08e48a1daff5084b2fd8f4f31986815f588b94165db3bc743442378fbb16dde6207cfc2262b90db70e5a8f7f1edee919eb8b0b8a0c1a4fbcd2a79dbdc78351e94e524104aa0623654d0a3f5bd30aada8de7e2de6632a3eec1a0da83bbdcefa5047bf8b0f7dec3295cb870d04b879bd796d1c244e13868dcf0e290c7bcff25653583bbd14e08b0748fd7978d9c284c59777282ca8f346cf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heated-sound",
   "metadata": {},
   "source": [
    "### 4.5 Debluring techniques\n",
    "Curranlty most of the techniques make use of machine learning. They outperform classical approaches by far, and are currently used in state-of-the-art upscaling methods. One of the most importnant and commonly used techniques are:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-lincoln",
   "metadata": {},
   "source": [
    "### Iterative approaches\n",
    "\n",
    "Exaple. **Iterative Poisson Map Algorithm**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-symphony",
   "metadata": {},
   "source": [
    "![](https://latex.codecogs.com/svg.latex?f^{n+1}%20=%20f^ne^{[H(\\frac{g}{Hf^n})-1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configured-senior",
   "metadata": {},
   "source": [
    "Where, fn+1is the new approximation from the previous f n, g is   the   captured   blurred   image, n is   the   number   of   the iterations, H is point spread function.In the first iteration, the value of (f n) is same  as  blurred  image g."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-roller",
   "metadata": {},
   "source": [
    "### Deep learning techniques\n",
    "There are many complex techniques involving some kind of DL. Most important are \n",
    "\n",
    "- **General regression neural networks**\n",
    "\n",
    "- **GANs**\n",
    "\n",
    "example of GAN for debluring\n",
    "![](https://miro.medium.com/max/1091/1*OhuvC1YUdHyLbGO6rWWHhA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "african-luxury",
   "metadata": {},
   "source": [
    "### Debluring medical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-student",
   "metadata": {},
   "source": [
    "The problem of debluring medical data is the nonstandard bluring model. A lot of modern deep learinig techniques aim to deblur those scans, with promissing results, but here comes the second part. \n",
    "\n",
    "Can you even tell which images below are blurred?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loose-legend",
   "metadata": {},
   "source": [
    "![](https://d3i71xaburhd42.cloudfront.net/094321a4644c35c5ae2a906e35a1676e8e523ef7/4-Figure1-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative-soldier",
   "metadata": {},
   "source": [
    "The first row is consists of naturally blured images, and the second one showcase deblured images. I couldn't find good quality images for and DL technique, so those were generated using Amended Landweber Algorithm. Natural blur in medical data is often hard to visualize, and major comparisons are made using only various metrics, which I didn't include here becouse, they wouldn't tell us much without understaning all of them and knowing numerous techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-threat",
   "metadata": {},
   "source": [
    "#### Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-federation",
   "metadata": {},
   "source": [
    "[Showcase of state-of-the-art upscaling technique](https://youtu.be/MwCgvYtOLS0) on Two Minute Papers YouTube channel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
