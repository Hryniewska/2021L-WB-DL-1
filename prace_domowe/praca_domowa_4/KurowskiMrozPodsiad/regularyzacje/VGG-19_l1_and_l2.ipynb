{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kurowskik/data_wb_iad/projekt/DeepCOVIDExplainer/noteboks\n"
     ]
    }
   ],
   "source": [
    "#pip install matplotlib\n",
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "os.chdir(\"/home/kurowskik/data_wb_iad/projekt/DeepCOVIDExplainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('../../data/x_train_undersampled.npy')\n",
    "y_train = np.load('../../data/y_train_undersampled.npy')\n",
    "x_test = np.load('../../data/x_test_undersampled.npy')\n",
    "y_test = np.load('../../data/y_test_undersampled.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5010, 224, 224, 3)\n",
      "(300, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5010,)\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kurowskik/data_wb_iad/projekt/DeepCOVIDExplainer\n"
     ]
    }
   ],
   "source": [
    "#x_train /= 255????\n",
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "print( os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/kurowskik/data_wb_iad/projekt/DeepCOVIDExplainer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kurowskik/wbiad3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kurowskik/wbiad3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kurowskik/wbiad3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kurowskik/wbiad3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kurowskik/wbiad3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kurowskik/wbiad3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/kurowskik/wbiad3.6/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kurowskik/wbiad3.6/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kurowskik/wbiad3.6/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kurowskik/wbiad3.6/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kurowskik/wbiad3.6/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kurowskik/wbiad3.6/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import time\n",
    "import csv\n",
    "from PIL import Image\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from keras import initializers\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential,load_model,Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import *\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras import callbacks\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as sklm\n",
    "from utils import lossprettifier\n",
    "from Classifier import VGG\n",
    "from Classifier.VGG import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducibility\n",
    "np.random.seed(3768)\n",
    "\n",
    "# use this environment flag to change which GPU to use \n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"  # specify which GPU(s) to be used\n",
    "\n",
    "#Get TensorFlow session\n",
    "def get_session(): \n",
    "    config = tf.ConfigProto() \n",
    "    config.gpu_options.allow_growth = True\n",
    "    return tf.Session(config=config) \n",
    "  \n",
    "# One hot encoding of labels \n",
    "def dense_to_one_hot(labels_dense,num_clases=4):\n",
    "    return np.eye(num_clases)[labels_dense]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-gpu==1.14.0 in /home/kurowskik/wbiad3.6/lib/python3.6/site-packages (1.14.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/kurowskik/wbiad3.6/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0) (1.36.1)\n",
      "Requirement already satisfied: gast>=0.2.0 in /home/kurowskik/wbiad3.6/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0) (0.4.0)\n",
      "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /home/kurowskik/wbiad3.6/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0) (1.14.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/kurowskik/wbiad3.6/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0) (1.0.8)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/kurowskik/wbiad3.6/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0) (0.12.0)\n",
      "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /home/kurowskik/wbiad3.6/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0) (1.14.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /home/kurowskik/wbiad3.6/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0) (3.15.5)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/kurowskik/wbiad3.6/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0) (0.8.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/kurowskik/wbiad3.6/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0) (1.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/kurowskik/wbiad3.6/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0) (1.12.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/kurowskik/wbiad3.6/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0) (0.36.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/kurowskik/wbiad3.6/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0) (1.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /home/kurowskik/wbiad3.6/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /home/kurowskik/wbiad3.6/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0) (1.18.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/kurowskik/wbiad3.6/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0) (1.1.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/kurowskik/wbiad3.6/lib/python3.6/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (1.0.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/kurowskik/wbiad3.6/lib/python3.6/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (54.1.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/kurowskik/wbiad3.6/lib/python3.6/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.3.4)\n",
      "Requirement already satisfied: h5py in /home/kurowskik/wbiad3.6/lib/python3.6/site-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14.0) (2.10.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /home/kurowskik/wbiad3.6/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.7.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/kurowskik/wbiad3.6/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /home/kurowskik/wbiad3.6/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.7.4.3)\n",
      "\u001b[33mYou are using pip version 18.1, however version 21.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow-gpu==1.14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15543396459861739968\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 7195976785103431447\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print( device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.client.session.Session object at 0x7fb761e9b710>\n"
     ]
    }
   ],
   "source": [
    "print( get_session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print( tf.test.is_gpu_available())\n",
    "print( tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing training and test sets\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = dense_to_one_hot(y_train,num_clases=4)\n",
    "y_valid= dense_to_one_hot(y_valid,num_clases=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kurowskik/wbiad3.6/lib/python3.6/site-packages/keras_preprocessing/image/image_data_generator.py:349: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, which overrides setting of `featurewise_center`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    }
   ],
   "source": [
    "#Image data generation for the training \n",
    "datagen = ImageDataGenerator(\n",
    "               featurewise_center = False, \n",
    "               samplewise_center = False,  # set each sample mean to 0\n",
    "               featurewise_std_normalization = True,  \n",
    "               samplewise_std_normalization = False)  \n",
    "\n",
    "datagen.fit(x_train) \n",
    "for i in range(len(x_test)):\n",
    "      x_test[i] = datagen.standardize(x_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kurowskik/wbiad3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kurowskik/wbiad3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kurowskik/wbiad3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kurowskik/wbiad3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kurowskik/wbiad3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kurowskik/wbiad3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kurowskik/wbiad3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/kurowskik/wbiad3.6/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kurowskik/wbiad3.6/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - 20s 628ms/step - loss: 1.4851 - acc: 0.3428 - val_loss: 1.3970 - val_acc: 0.3433\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 15s 479ms/step - loss: 1.3750 - acc: 0.4053 - val_loss: 1.3205 - val_acc: 0.5768\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 15s 463ms/step - loss: 1.2556 - acc: 0.5771 - val_loss: 1.1981 - val_acc: 0.5948\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 14s 453ms/step - loss: 1.2268 - acc: 0.5771 - val_loss: 1.1473 - val_acc: 0.5988\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 14s 446ms/step - loss: 1.1939 - acc: 0.5886 - val_loss: 1.1120 - val_acc: 0.6367\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 14s 441ms/step - loss: 1.1404 - acc: 0.6289 - val_loss: 1.0648 - val_acc: 0.6387\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 14s 441ms/step - loss: 1.1330 - acc: 0.6240 - val_loss: 1.0063 - val_acc: 0.7046\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 14s 426ms/step - loss: 1.0340 - acc: 0.6914 - val_loss: 1.0333 - val_acc: 0.6886\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 15s 462ms/step - loss: 1.0470 - acc: 0.6749 - val_loss: 1.0797 - val_acc: 0.6627\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 14s 438ms/step - loss: 1.0842 - acc: 0.6260 - val_loss: 0.9820 - val_acc: 0.6906\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 15s 454ms/step - loss: 1.0337 - acc: 0.6787 - val_loss: 0.9323 - val_acc: 0.7325\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 1.0604 - acc: 0.6680 - val_loss: 1.0622 - val_acc: 0.6527\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 14s 448ms/step - loss: 1.0734 - acc: 0.6826 - val_loss: 0.9991 - val_acc: 0.7026\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 14s 441ms/step - loss: 1.0361 - acc: 0.6757 - val_loss: 0.9804 - val_acc: 0.7345\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 0.9895 - acc: 0.6904 - val_loss: 0.9981 - val_acc: 0.6806\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 1.0205 - acc: 0.6768 - val_loss: 0.9597 - val_acc: 0.7106\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 15s 475ms/step - loss: 0.9779 - acc: 0.7021 - val_loss: 1.1140 - val_acc: 0.6068\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 15s 455ms/step - loss: 1.0140 - acc: 0.6849 - val_loss: 0.9194 - val_acc: 0.7126\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 14s 446ms/step - loss: 1.0209 - acc: 0.6846 - val_loss: 0.9548 - val_acc: 0.7246\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 0.9802 - acc: 0.7041 - val_loss: 0.9362 - val_acc: 0.7186\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 13s 419ms/step - loss: 0.9835 - acc: 0.7188 - val_loss: 0.8756 - val_acc: 0.7545\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 13s 417ms/step - loss: 0.9516 - acc: 0.7168 - val_loss: 0.9250 - val_acc: 0.7465\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 13s 400ms/step - loss: 0.9464 - acc: 0.7265 - val_loss: 0.9385 - val_acc: 0.7345\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 13s 412ms/step - loss: 0.9823 - acc: 0.7139 - val_loss: 0.8768 - val_acc: 0.7565\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 13s 412ms/step - loss: 0.9255 - acc: 0.7383 - val_loss: 0.8699 - val_acc: 0.7725\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 14s 423ms/step - loss: 0.9516 - acc: 0.7109 - val_loss: 0.9013 - val_acc: 0.7325\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 13s 411ms/step - loss: 0.9212 - acc: 0.7238 - val_loss: 0.8123 - val_acc: 0.7824\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.9097 - acc: 0.7432 - val_loss: 0.8700 - val_acc: 0.7605\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 13s 417ms/step - loss: 0.9260 - acc: 0.7285 - val_loss: 0.8407 - val_acc: 0.7685\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 15s 460ms/step - loss: 0.9209 - acc: 0.7246 - val_loss: 0.8216 - val_acc: 0.7705\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 14s 439ms/step - loss: 0.8796 - acc: 0.7523 - val_loss: 0.8199 - val_acc: 0.7725\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 15s 464ms/step - loss: 0.8957 - acc: 0.7441 - val_loss: 0.9069 - val_acc: 0.7365\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 16s 509ms/step - loss: 0.9243 - acc: 0.7373 - val_loss: 0.8274 - val_acc: 0.7824\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 16s 488ms/step - loss: 0.9211 - acc: 0.7275 - val_loss: 0.8541 - val_acc: 0.7525\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 0.8809 - acc: 0.7480 - val_loss: 0.8554 - val_acc: 0.7445\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 0.8743 - acc: 0.7558 - val_loss: 0.8289 - val_acc: 0.7784\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 15s 476ms/step - loss: 0.9106 - acc: 0.7275 - val_loss: 0.8652 - val_acc: 0.7505\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 14s 448ms/step - loss: 0.9104 - acc: 0.7432 - val_loss: 0.8070 - val_acc: 0.7764\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 0.8959 - acc: 0.7324 - val_loss: 0.8796 - val_acc: 0.7465\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 14s 449ms/step - loss: 0.9407 - acc: 0.7170 - val_loss: 0.8671 - val_acc: 0.7705\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 14s 446ms/step - loss: 0.9215 - acc: 0.7266 - val_loss: 0.8095 - val_acc: 0.7784\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 15s 483ms/step - loss: 0.8255 - acc: 0.7666 - val_loss: 0.8391 - val_acc: 0.7665\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 15s 456ms/step - loss: 0.9160 - acc: 0.7188 - val_loss: 0.7996 - val_acc: 0.7844\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 15s 461ms/step - loss: 0.9730 - acc: 0.6865 - val_loss: 0.8501 - val_acc: 0.7824\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 0.8927 - acc: 0.7339 - val_loss: 0.8955 - val_acc: 0.7365\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 0.9353 - acc: 0.7197 - val_loss: 0.8461 - val_acc: 0.7565\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 15s 483ms/step - loss: 0.9255 - acc: 0.7109 - val_loss: 0.9120 - val_acc: 0.7265\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 15s 482ms/step - loss: 0.9987 - acc: 0.6924 - val_loss: 1.0379 - val_acc: 0.6547\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 14s 451ms/step - loss: 0.9148 - acc: 0.7298 - val_loss: 0.9124 - val_acc: 0.7206\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 15s 469ms/step - loss: 0.9597 - acc: 0.7129 - val_loss: 0.8910 - val_acc: 0.7385\n"
     ]
    }
   ],
   "source": [
    "#Defining hyperparameters\n",
    "batch_Size = 32\n",
    "steps_Per_Epoch = 32\n",
    "numEpochs = 50\n",
    "\n",
    "#Instantating VGG19 model\n",
    "model = VGG19_l1_and_l2((224,224,3),4) #VGG19_dense for revised VGG19, VGG19 for VGG19. Please pay attention to VGG16(), chnage the input shape and class number in VGG.py.\n",
    "\n",
    "#Creating an optimizers\n",
    "adaDelta = keras.optimizers.Adadelta(lr=1.0, rho=0.95)\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.95, nesterov=True)\n",
    "model.compile(optimizer = sgd , loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "#Creating early stopping \n",
    "earlystop = EarlyStopping(monitor = 'val_accuracy', min_delta = 0, patience = 50, verbose = 1, mode = 'auto', restore_best_weights = True)       \n",
    "\n",
    "train_generator = datagen.flow(x_train, y_train, batch_size = batch_Size)\n",
    "validation_generator = datagen.flow(x_valid, y_valid, batch_size = batch_Size)\n",
    "\n",
    "# Model training\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = steps_Per_Epoch,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = 16,\n",
    "    epochs = numEpochs,\n",
    "    shuffle = True, \n",
    "    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = \"VGG19_COVID19_undersampled_l1_and_l2.h5\"\n",
    "resultPath = 'VGG19_COVID19_undersampled_l1_and_l2.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     0 | LossA: 1.49(+0.00%) \u001b[0m\t| LossAB: 1.40(+0.00%) \u001b[0m\t\n",
      "Epoch     1 | LossA: \u001b[32m1.37(-7.42%) ▼\u001b[0m\t| LossAB: \u001b[32m1.32(-5.48%) ▼\u001b[0m\t\n",
      "Epoch     2 | LossA: \u001b[32m1.26(-8.68%) ▼\u001b[0m\t| LossAB: \u001b[32m1.20(-9.27%) ▼\u001b[0m\t\n",
      "Epoch     3 | LossA: \u001b[32m1.23(-2.30%) ▼\u001b[0m\t| LossAB: \u001b[32m1.15(-4.24%) ▼\u001b[0m\t\n",
      "Epoch     4 | LossA: \u001b[32m1.19(-2.68%) ▼\u001b[0m\t| LossAB: \u001b[32m1.11(-3.08%) ▼\u001b[0m\t\n",
      "Epoch     5 | LossA: \u001b[32m1.14(-4.48%) ▼\u001b[0m\t| LossAB: \u001b[32m1.06(-4.25%) ▼\u001b[0m\t\n",
      "Epoch     6 | LossA: \u001b[32m1.13(-0.65%) ▼\u001b[0m\t| LossAB: \u001b[32m1.01(-5.49%) ▼\u001b[0m\t\n",
      "Epoch     7 | LossA: \u001b[32m1.03(-8.74%) ▼\u001b[0m\t| LossAB: \u001b[91m1.03(+2.69%) ▲\u001b[0m\t\n",
      "Epoch     8 | LossA: \u001b[91m1.05(+1.28%) ▲\u001b[0m\t| LossAB: \u001b[91m1.08(+4.48%) ▲\u001b[0m\t\n",
      "Epoch     9 | LossA: \u001b[91m1.08(+3.53%) ▲\u001b[0m\t| LossAB: \u001b[32m0.98(-9.05%) ▼\u001b[0m\t\n",
      "Epoch    10 | LossA: \u001b[32m1.03(-4.66%) ▼\u001b[0m\t| LossAB: \u001b[32m0.93(-5.06%) ▼\u001b[0m\t\n",
      "Epoch    11 | LossA: \u001b[91m1.06(+2.59%) ▲\u001b[0m\t| LossAB: \u001b[91m1.06(+13.94%) ▲\u001b[0m\t\n",
      "Epoch    12 | LossA: \u001b[91m1.07(+1.22%) ▲\u001b[0m\t| LossAB: \u001b[32m1.00(-5.94%) ▼\u001b[0m\t\n",
      "Epoch    13 | LossA: \u001b[32m1.04(-3.48%) ▼\u001b[0m\t| LossAB: \u001b[32m0.98(-1.87%) ▼\u001b[0m\t\n",
      "Epoch    14 | LossA: \u001b[32m0.99(-4.49%) ▼\u001b[0m\t| LossAB: \u001b[91m1.00(+1.80%) ▲\u001b[0m\t\n",
      "Epoch    15 | LossA: \u001b[91m1.02(+3.13%) ▲\u001b[0m\t| LossAB: \u001b[32m0.96(-3.85%) ▼\u001b[0m\t\n",
      "Epoch    16 | LossA: \u001b[32m0.98(-4.17%) ▼\u001b[0m\t| LossAB: \u001b[91m1.11(+16.07%) ▲\u001b[0m\t\n",
      "Epoch    17 | LossA: \u001b[91m1.01(+3.73%) ▲\u001b[0m\t| LossAB: \u001b[32m0.92(-17.46%) ▼\u001b[0m\t\n",
      "Epoch    18 | LossA: \u001b[91m1.02(+0.64%) ▲\u001b[0m\t| LossAB: \u001b[91m0.95(+3.84%) ▲\u001b[0m\t\n",
      "Epoch    19 | LossA: \u001b[32m0.98(-3.98%) ▼\u001b[0m\t| LossAB: \u001b[32m0.94(-1.94%) ▼\u001b[0m\t\n",
      "Epoch    20 | LossA: \u001b[91m0.98(+0.33%) ▲\u001b[0m\t| LossAB: \u001b[32m0.88(-6.47%) ▼\u001b[0m\t\n",
      "Epoch    21 | LossA: \u001b[32m0.95(-3.24%) ▼\u001b[0m\t| LossAB: \u001b[91m0.93(+5.64%) ▲\u001b[0m\t\n",
      "Epoch    22 | LossA: \u001b[32m0.95(-0.63%) ▼\u001b[0m\t| LossAB: \u001b[91m0.94(+1.46%) ▲\u001b[0m\t\n",
      "Epoch    23 | LossA: \u001b[91m0.98(+3.88%) ▲\u001b[0m\t| LossAB: \u001b[32m0.88(-6.57%) ▼\u001b[0m\t\n",
      "Epoch    24 | LossA: \u001b[32m0.93(-5.79%) ▼\u001b[0m\t| LossAB: \u001b[32m0.87(-0.79%) ▼\u001b[0m\t\n",
      "Epoch    25 | LossA: \u001b[91m0.95(+2.83%) ▲\u001b[0m\t| LossAB: \u001b[91m0.90(+3.62%) ▲\u001b[0m\t\n",
      "Epoch    26 | LossA: \u001b[32m0.92(-3.16%) ▼\u001b[0m\t| LossAB: \u001b[32m0.81(-9.88%) ▼\u001b[0m\t\n",
      "Epoch    27 | LossA: \u001b[32m0.91(-1.29%) ▼\u001b[0m\t| LossAB: \u001b[91m0.87(+7.10%) ▲\u001b[0m\t\n",
      "Epoch    28 | LossA: \u001b[91m0.93(+1.79%) ▲\u001b[0m\t| LossAB: \u001b[32m0.84(-3.37%) ▼\u001b[0m\t\n",
      "Epoch    29 | LossA: \u001b[32m0.92(-0.56%) ▼\u001b[0m\t| LossAB: \u001b[32m0.82(-2.26%) ▼\u001b[0m\t\n",
      "Epoch    30 | LossA: \u001b[32m0.88(-4.45%) ▼\u001b[0m\t| LossAB: \u001b[32m0.82(-0.21%) ▼\u001b[0m\t\n",
      "Epoch    31 | LossA: \u001b[91m0.90(+1.79%) ▲\u001b[0m\t| LossAB: \u001b[91m0.91(+10.61%) ▲\u001b[0m\t\n",
      "Epoch    32 | LossA: \u001b[91m0.92(+3.19%) ▲\u001b[0m\t| LossAB: \u001b[32m0.83(-8.77%) ▼\u001b[0m\t\n",
      "Epoch    33 | LossA: \u001b[32m0.92(-0.35%) ▼\u001b[0m\t| LossAB: \u001b[91m0.85(+3.22%) ▲\u001b[0m\t\n",
      "Epoch    34 | LossA: \u001b[32m0.88(-4.36%) ▼\u001b[0m\t| LossAB: \u001b[91m0.86(+0.16%) ▲\u001b[0m\t\n",
      "Epoch    35 | LossA: \u001b[32m0.87(-0.75%) ▼\u001b[0m\t| LossAB: \u001b[32m0.83(-3.11%) ▼\u001b[0m\t\n",
      "Epoch    36 | LossA: \u001b[91m0.91(+4.15%) ▲\u001b[0m\t| LossAB: \u001b[91m0.87(+4.38%) ▲\u001b[0m\t\n",
      "Epoch    37 | LossA: \u001b[32m0.91(-0.01%) ▼\u001b[0m\t| LossAB: \u001b[32m0.81(-6.72%) ▼\u001b[0m\t\n",
      "Epoch    38 | LossA: \u001b[32m0.90(-1.59%) ▼\u001b[0m\t| LossAB: \u001b[91m0.88(+8.99%) ▲\u001b[0m\t\n",
      "Epoch    39 | LossA: \u001b[91m0.94(+4.95%) ▲\u001b[0m\t| LossAB: \u001b[32m0.87(-1.42%) ▼\u001b[0m\t\n",
      "Epoch    40 | LossA: \u001b[32m0.92(-1.99%) ▼\u001b[0m\t| LossAB: \u001b[32m0.81(-6.65%) ▼\u001b[0m\t\n",
      "Epoch    41 | LossA: \u001b[32m0.83(-10.42%) ▼\u001b[0m\t| LossAB: \u001b[91m0.84(+3.66%) ▲\u001b[0m\t\n",
      "Epoch    42 | LossA: \u001b[91m0.92(+10.96%) ▲\u001b[0m\t| LossAB: \u001b[32m0.80(-4.70%) ▼\u001b[0m\t\n",
      "Epoch    43 | LossA: \u001b[91m0.97(+6.22%) ▲\u001b[0m\t| LossAB: \u001b[91m0.85(+6.31%) ▲\u001b[0m\t\n",
      "Epoch    44 | LossA: \u001b[32m0.89(-8.21%) ▼\u001b[0m\t| LossAB: \u001b[91m0.90(+5.35%) ▲\u001b[0m\t\n",
      "Epoch    45 | LossA: \u001b[91m0.94(+4.73%) ▲\u001b[0m\t| LossAB: \u001b[32m0.85(-5.52%) ▼\u001b[0m\t\n",
      "Epoch    46 | LossA: \u001b[32m0.93(-1.04%) ▼\u001b[0m\t| LossAB: \u001b[91m0.91(+7.79%) ▲\u001b[0m\t\n",
      "Epoch    47 | LossA: \u001b[91m1.00(+7.91%) ▲\u001b[0m\t| LossAB: \u001b[91m1.04(+13.81%) ▲\u001b[0m\t\n",
      "Epoch    48 | LossA: \u001b[32m0.92(-8.37%) ▼\u001b[0m\t| LossAB: \u001b[32m0.91(-12.10%) ▼\u001b[0m\t\n",
      "300/300 [==============================] - 4s 12ms/step\n",
      "Accuracy: 0.7233333333333334\n"
     ]
    }
   ],
   "source": [
    "y_test_oh = dense_to_one_hot(y_test, num_clases=4)\n",
    "\n",
    "# visualizing losses and accuracy\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "#Observing the losses but can be commented out as it's not mandatory \n",
    "reporter = lossprettifier.LossPrettifier(show_percentage=True)\n",
    "\n",
    "for i in range(numEpochs-1):\n",
    "    reporter(epoch=i, LossA = train_loss[i], LossAB = val_loss[i])\n",
    "\n",
    "# Model evaluation \n",
    "#score, acc = model.evaluate(x_test, y_test_oh, batch_size=batch_Size)\n",
    "score, acc = model.evaluate(x_test, y_test_oh, batch_size=batch_Size)\n",
    "print(\"Accuracy:\", acc)\n",
    "\n",
    "#if acc>0.675:\n",
    "model.save_weights(modelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.71      0.74       100\n",
      "           1       0.77      0.64      0.70       100\n",
      "           2       0.66      0.82      0.73       100\n",
      "\n",
      "    accuracy                           0.72       300\n",
      "   macro avg       0.73      0.72      0.72       300\n",
      "weighted avg       0.73      0.72      0.72       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_pred = y_pred.reshape(len(y_test), 4)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Writing results on file\n",
    "f = open(resultPath,'a') #create classification report\n",
    "f.write(classification_report(y_test, y_pred))\n",
    "f.write(str(sklm.cohen_kappa_score(y_test, y_pred))+\",\"+str(acc)+\",\"+str(score)+\"\\n\")\n",
    "\n",
    "#Print class-wise classification metrics\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 2)       56        \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 2)       38        \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 2)       0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 4)       76        \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 4)       148       \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 4)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 8)         296       \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 8)         584       \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 8)         584       \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 8)         584       \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 8)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 16)        1168      \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 487,874\n",
      "Trainable params: 487,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.array(['normal', 'COVID19', 'pneumonia']))\n",
    "disp.plot(cmap='Blues') \n",
    "disp.ax_.get_images()[0].set_clim(0, 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wbiad3.6",
   "language": "python",
   "name": "wbiad3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
