{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kurowskik/data_wb_iad/projekt/DeepCOVIDExplainer/noteboks\n"
     ]
    }
   ],
   "source": [
    "#pip install matplotlib\n",
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "os.chdir(\"/home/kurowskik/data_wb_iad/projekt/DeepCOVIDExplainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('../../data/x_train_undersampled.npy')\n",
    "y_train = np.load('../../data/y_train_undersampled.npy')\n",
    "x_test = np.load('../../data/x_test_undersampled.npy')\n",
    "y_test = np.load('../../data/y_test_undersampled.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5010, 224, 224, 3)\n",
      "(300, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5010,)\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kurowskik/data_wb_iad/projekt/DeepCOVIDExplainer\n"
     ]
    }
   ],
   "source": [
    "#x_train /= 255????\n",
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "print( os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kurowskik/wbiad3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kurowskik/wbiad3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kurowskik/wbiad3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kurowskik/wbiad3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kurowskik/wbiad3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kurowskik/wbiad3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/kurowskik/wbiad3.6/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kurowskik/wbiad3.6/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kurowskik/wbiad3.6/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kurowskik/wbiad3.6/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kurowskik/wbiad3.6/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kurowskik/wbiad3.6/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import time\n",
    "import csv\n",
    "from PIL import Image\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from keras import initializers\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential,load_model,Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import *\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras import callbacks\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as sklm\n",
    "from utils import lossprettifier\n",
    "from Classifier import VGG\n",
    "from Classifier.VGG import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducibility\n",
    "np.random.seed(3768)\n",
    "\n",
    "# use this environment flag to change which GPU to use \n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"  # specify which GPU(s) to be used\n",
    "\n",
    "#Get TensorFlow session\n",
    "def get_session(): \n",
    "    config = tf.ConfigProto() \n",
    "    config.gpu_options.allow_growth = True\n",
    "    return tf.Session(config=config) \n",
    "  \n",
    "# One hot encoding of labels \n",
    "def dense_to_one_hot(labels_dense,num_clases=4):\n",
    "    return np.eye(num_clases)[labels_dense]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing training and test sets\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = dense_to_one_hot(y_train,num_clases=4)\n",
    "y_valid= dense_to_one_hot(y_valid,num_clases=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kurowskik/wbiad3.6/lib/python3.6/site-packages/keras_preprocessing/image/image_data_generator.py:349: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, which overrides setting of `featurewise_center`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    }
   ],
   "source": [
    "#Image data generation for the training \n",
    "datagen = ImageDataGenerator(\n",
    "               featurewise_center = False, \n",
    "               samplewise_center = False,  # set each sample mean to 0\n",
    "               featurewise_std_normalization = True,  \n",
    "               samplewise_std_normalization = False)  \n",
    "\n",
    "datagen.fit(x_train) \n",
    "for i in range(len(x_test)):\n",
    "      x_test[i] = datagen.standardize(x_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kurowskik/wbiad3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kurowskik/wbiad3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kurowskik/wbiad3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kurowskik/wbiad3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kurowskik/wbiad3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kurowskik/wbiad3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kurowskik/wbiad3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/kurowskik/wbiad3.6/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kurowskik/wbiad3.6/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - 20s 628ms/step - loss: 1.3025 - acc: 0.3379 - val_loss: 1.2247 - val_acc: 0.3433\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 15s 463ms/step - loss: 1.1878 - acc: 0.4385 - val_loss: 1.1134 - val_acc: 0.5848\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 14s 447ms/step - loss: 1.0728 - acc: 0.5693 - val_loss: 1.0225 - val_acc: 0.5968\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 16s 504ms/step - loss: 1.0242 - acc: 0.6035 - val_loss: 1.0003 - val_acc: 0.5888\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 1.0164 - acc: 0.5601 - val_loss: 0.9226 - val_acc: 0.6307\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 14s 426ms/step - loss: 0.9603 - acc: 0.6328 - val_loss: 0.9095 - val_acc: 0.6507\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 14s 450ms/step - loss: 0.9867 - acc: 0.6064 - val_loss: 0.8639 - val_acc: 0.6806\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 0.8849 - acc: 0.6787 - val_loss: 0.8461 - val_acc: 0.6707\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 14s 436ms/step - loss: 0.9008 - acc: 0.6661 - val_loss: 0.9240 - val_acc: 0.6447\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 14s 423ms/step - loss: 0.8814 - acc: 0.6680 - val_loss: 0.7981 - val_acc: 0.7006\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 15s 461ms/step - loss: 0.8609 - acc: 0.6943 - val_loss: 0.8312 - val_acc: 0.6806\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 14s 447ms/step - loss: 0.8384 - acc: 0.7051 - val_loss: 0.8081 - val_acc: 0.7066\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 16s 511ms/step - loss: 0.8491 - acc: 0.7041 - val_loss: 0.7424 - val_acc: 0.7405\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 16s 496ms/step - loss: 0.8659 - acc: 0.6787 - val_loss: 0.7737 - val_acc: 0.7265\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 17s 530ms/step - loss: 0.7857 - acc: 0.7256 - val_loss: 0.7294 - val_acc: 0.7365\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 16s 493ms/step - loss: 0.8040 - acc: 0.7100 - val_loss: 0.8460 - val_acc: 0.6886\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 14s 453ms/step - loss: 0.8281 - acc: 0.7129 - val_loss: 0.7276 - val_acc: 0.7465\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 14s 440ms/step - loss: 0.8163 - acc: 0.6937 - val_loss: 0.7597 - val_acc: 0.7305\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 14s 450ms/step - loss: 0.8585 - acc: 0.6836 - val_loss: 0.7423 - val_acc: 0.7385\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.8690 - acc: 0.6572 - val_loss: 0.8900 - val_acc: 0.6467\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 13s 413ms/step - loss: 0.8772 - acc: 0.6797 - val_loss: 0.7614 - val_acc: 0.7226\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 14s 427ms/step - loss: 0.8037 - acc: 0.7129 - val_loss: 0.7043 - val_acc: 0.7665\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 13s 416ms/step - loss: 0.7551 - acc: 0.7459 - val_loss: 0.7020 - val_acc: 0.7565\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 0.8016 - acc: 0.7051 - val_loss: 0.7138 - val_acc: 0.7565\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 0.7913 - acc: 0.7100 - val_loss: 0.7552 - val_acc: 0.7186\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.7965 - acc: 0.7246 - val_loss: 0.7176 - val_acc: 0.7485\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 13s 413ms/step - loss: 0.7766 - acc: 0.7123 - val_loss: 0.6464 - val_acc: 0.8064\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 13s 415ms/step - loss: 0.8950 - acc: 0.6641 - val_loss: 0.9118 - val_acc: 0.6387\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 14s 429ms/step - loss: 0.9047 - acc: 0.6592 - val_loss: 0.7812 - val_acc: 0.7345\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 13s 419ms/step - loss: 0.8188 - acc: 0.6943 - val_loss: 0.7683 - val_acc: 0.7345\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 13s 413ms/step - loss: 0.8251 - acc: 0.6973 - val_loss: 0.7227 - val_acc: 0.7485\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.7780 - acc: 0.7305 - val_loss: 0.7330 - val_acc: 0.7565\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 13s 413ms/step - loss: 0.7541 - acc: 0.7383 - val_loss: 0.8026 - val_acc: 0.6946\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 14s 427ms/step - loss: 0.9718 - acc: 0.6104 - val_loss: 0.8827 - val_acc: 0.6707\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 14s 438ms/step - loss: 0.8692 - acc: 0.6797 - val_loss: 0.8075 - val_acc: 0.6906\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 13s 414ms/step - loss: 0.8078 - acc: 0.7089 - val_loss: 0.7708 - val_acc: 0.7445\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.8779 - acc: 0.6738 - val_loss: 0.7968 - val_acc: 0.7046\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 0.8043 - acc: 0.7158 - val_loss: 0.8079 - val_acc: 0.6806\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 13s 414ms/step - loss: 0.8326 - acc: 0.6895 - val_loss: 0.8543 - val_acc: 0.6747\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 13s 419ms/step - loss: 0.8926 - acc: 0.6477 - val_loss: 0.7915 - val_acc: 0.7026\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 13s 415ms/step - loss: 0.9024 - acc: 0.6553 - val_loss: 0.8997 - val_acc: 0.6547\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 13s 416ms/step - loss: 0.9272 - acc: 0.6387 - val_loss: 0.9832 - val_acc: 0.5888\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 13s 418ms/step - loss: 1.0138 - acc: 0.5781 - val_loss: 0.8650 - val_acc: 0.6527\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 13s 412ms/step - loss: 0.8795 - acc: 0.6748 - val_loss: 0.8271 - val_acc: 0.7026\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 14s 422ms/step - loss: 0.8343 - acc: 0.6952 - val_loss: 0.8882 - val_acc: 0.6647\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 0.9271 - acc: 0.6416 - val_loss: 1.0123 - val_acc: 0.5848\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 0.9936 - acc: 0.5996 - val_loss: 0.9699 - val_acc: 0.6068\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 13s 419ms/step - loss: 1.0019 - acc: 0.5752 - val_loss: 0.9748 - val_acc: 0.6028\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 13s 404ms/step - loss: 0.9658 - acc: 0.6058 - val_loss: 0.9252 - val_acc: 0.6367\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 13s 414ms/step - loss: 0.9259 - acc: 0.6240 - val_loss: 0.9275 - val_acc: 0.6327\n"
     ]
    }
   ],
   "source": [
    "from Classifier.VGG_with_l2 import *\n",
    "\n",
    "#Defining hyperparameters\n",
    "batch_Size = 32\n",
    "steps_Per_Epoch = 32\n",
    "numEpochs = 50\n",
    "\n",
    "#Instantating VGG19 model\n",
    "model = VGG19_l2((224,224,3),4) #VGG19_dense for revised VGG19, VGG19 for VGG19. Please pay attention to VGG16(), chnage the input shape and class number in VGG.py.\n",
    "\n",
    "#Creating an optimizers\n",
    "adaDelta = keras.optimizers.Adadelta(lr=1.0, rho=0.95)\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.95, nesterov=True)\n",
    "model.compile(optimizer = sgd , loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "#Creating early stopping \n",
    "earlystop = EarlyStopping(monitor = 'val_accuracy', min_delta = 0, patience = 50, verbose = 1, mode = 'auto', restore_best_weights = True)       \n",
    "\n",
    "train_generator = datagen.flow(x_train, y_train, batch_size = batch_Size)\n",
    "validation_generator = datagen.flow(x_valid, y_valid, batch_size = batch_Size)\n",
    "\n",
    "# Model training\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = steps_Per_Epoch,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = 16,\n",
    "    epochs = numEpochs,\n",
    "    shuffle = True, \n",
    "    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = \"VGG19_COVID19_undersampled_l2.h5\"\n",
    "resultPath = 'VGG19_COVID19_undersampled_l2.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     0 | LossA: 1.30(+0.00%) \u001b[0m\t| LossAB: 1.22(+0.00%) \u001b[0m\t\n",
      "Epoch     1 | LossA: \u001b[32m1.19(-8.81%) ▼\u001b[0m\t| LossAB: \u001b[32m1.11(-9.09%) ▼\u001b[0m\t\n",
      "Epoch     2 | LossA: \u001b[32m1.07(-9.68%) ▼\u001b[0m\t| LossAB: \u001b[32m1.02(-8.17%) ▼\u001b[0m\t\n",
      "Epoch     3 | LossA: \u001b[32m1.02(-4.53%) ▼\u001b[0m\t| LossAB: \u001b[32m1.00(-2.17%) ▼\u001b[0m\t\n",
      "Epoch     4 | LossA: \u001b[32m1.02(-0.77%) ▼\u001b[0m\t| LossAB: \u001b[32m0.92(-7.76%) ▼\u001b[0m\t\n",
      "Epoch     5 | LossA: \u001b[32m0.96(-5.51%) ▼\u001b[0m\t| LossAB: \u001b[32m0.91(-1.42%) ▼\u001b[0m\t\n",
      "Epoch     6 | LossA: \u001b[91m0.99(+2.75%) ▲\u001b[0m\t| LossAB: \u001b[32m0.86(-5.01%) ▼\u001b[0m\t\n",
      "Epoch     7 | LossA: \u001b[32m0.88(-10.32%) ▼\u001b[0m\t| LossAB: \u001b[32m0.85(-2.06%) ▼\u001b[0m\t\n",
      "Epoch     8 | LossA: \u001b[91m0.90(+1.83%) ▲\u001b[0m\t| LossAB: \u001b[91m0.92(+9.20%) ▲\u001b[0m\t\n",
      "Epoch     9 | LossA: \u001b[32m0.88(-2.19%) ▼\u001b[0m\t| LossAB: \u001b[32m0.80(-13.62%) ▼\u001b[0m\t\n",
      "Epoch    10 | LossA: \u001b[32m0.86(-2.33%) ▼\u001b[0m\t| LossAB: \u001b[91m0.83(+4.15%) ▲\u001b[0m\t\n",
      "Epoch    11 | LossA: \u001b[32m0.84(-2.62%) ▼\u001b[0m\t| LossAB: \u001b[32m0.81(-2.78%) ▼\u001b[0m\t\n",
      "Epoch    12 | LossA: \u001b[91m0.85(+1.28%) ▲\u001b[0m\t| LossAB: \u001b[32m0.74(-8.14%) ▼\u001b[0m\t\n",
      "Epoch    13 | LossA: \u001b[91m0.87(+1.96%) ▲\u001b[0m\t| LossAB: \u001b[91m0.77(+4.23%) ▲\u001b[0m\t\n",
      "Epoch    14 | LossA: \u001b[32m0.79(-9.24%) ▼\u001b[0m\t| LossAB: \u001b[32m0.73(-5.72%) ▼\u001b[0m\t\n",
      "Epoch    15 | LossA: \u001b[91m0.80(+2.33%) ▲\u001b[0m\t| LossAB: \u001b[91m0.85(+15.97%) ▲\u001b[0m\t\n",
      "Epoch    16 | LossA: \u001b[91m0.83(+3.00%) ▲\u001b[0m\t| LossAB: \u001b[32m0.73(-13.99%) ▼\u001b[0m\t\n",
      "Epoch    17 | LossA: \u001b[32m0.82(-1.36%) ▼\u001b[0m\t| LossAB: \u001b[91m0.76(+4.41%) ▲\u001b[0m\t\n",
      "Epoch    18 | LossA: \u001b[91m0.86(+5.10%) ▲\u001b[0m\t| LossAB: \u001b[32m0.74(-2.29%) ▼\u001b[0m\t\n",
      "Epoch    19 | LossA: \u001b[91m0.87(+1.22%) ▲\u001b[0m\t| LossAB: \u001b[91m0.89(+19.89%) ▲\u001b[0m\t\n",
      "Epoch    20 | LossA: \u001b[91m0.88(+0.95%) ▲\u001b[0m\t| LossAB: \u001b[32m0.76(-14.44%) ▼\u001b[0m\t\n",
      "Epoch    21 | LossA: \u001b[32m0.80(-8.38%) ▼\u001b[0m\t| LossAB: \u001b[32m0.70(-7.51%) ▼\u001b[0m\t\n",
      "Epoch    22 | LossA: \u001b[32m0.75(-6.09%) ▼\u001b[0m\t| LossAB: \u001b[32m0.70(-0.32%) ▼\u001b[0m\t\n",
      "Epoch    23 | LossA: \u001b[91m0.80(+6.21%) ▲\u001b[0m\t| LossAB: \u001b[91m0.71(+1.69%) ▲\u001b[0m\t\n",
      "Epoch    24 | LossA: \u001b[32m0.79(-1.29%) ▼\u001b[0m\t| LossAB: \u001b[91m0.76(+5.80%) ▲\u001b[0m\t\n",
      "Epoch    25 | LossA: \u001b[91m0.80(+0.67%) ▲\u001b[0m\t| LossAB: \u001b[32m0.72(-4.98%) ▼\u001b[0m\t\n",
      "Epoch    26 | LossA: \u001b[32m0.78(-2.46%) ▼\u001b[0m\t| LossAB: \u001b[32m0.65(-9.93%) ▼\u001b[0m\t\n",
      "Epoch    27 | LossA: \u001b[91m0.90(+15.20%) ▲\u001b[0m\t| LossAB: \u001b[91m0.91(+41.07%) ▲\u001b[0m\t\n",
      "Epoch    28 | LossA: \u001b[91m0.90(+1.08%) ▲\u001b[0m\t| LossAB: \u001b[32m0.78(-14.33%) ▼\u001b[0m\t\n",
      "Epoch    29 | LossA: \u001b[32m0.82(-9.50%) ▼\u001b[0m\t| LossAB: \u001b[32m0.77(-1.66%) ▼\u001b[0m\t\n",
      "Epoch    30 | LossA: \u001b[91m0.83(+0.84%) ▲\u001b[0m\t| LossAB: \u001b[32m0.72(-5.93%) ▼\u001b[0m\t\n",
      "Epoch    31 | LossA: \u001b[32m0.78(-5.77%) ▼\u001b[0m\t| LossAB: \u001b[91m0.73(+1.43%) ▲\u001b[0m\t\n",
      "Epoch    32 | LossA: \u001b[32m0.75(-3.07%) ▼\u001b[0m\t| LossAB: \u001b[91m0.80(+9.49%) ▲\u001b[0m\t\n",
      "Epoch    33 | LossA: \u001b[91m0.97(+28.87%) ▲\u001b[0m\t| LossAB: \u001b[91m0.88(+9.98%) ▲\u001b[0m\t\n",
      "Epoch    34 | LossA: \u001b[32m0.87(-10.55%) ▼\u001b[0m\t| LossAB: \u001b[32m0.81(-8.51%) ▼\u001b[0m\t\n",
      "Epoch    35 | LossA: \u001b[32m0.81(-7.15%) ▼\u001b[0m\t| LossAB: \u001b[32m0.77(-4.55%) ▼\u001b[0m\t\n",
      "Epoch    36 | LossA: \u001b[91m0.88(+8.78%) ▲\u001b[0m\t| LossAB: \u001b[91m0.80(+3.37%) ▲\u001b[0m\t\n",
      "Epoch    37 | LossA: \u001b[32m0.80(-8.38%) ▼\u001b[0m\t| LossAB: \u001b[91m0.81(+1.39%) ▲\u001b[0m\t\n",
      "Epoch    38 | LossA: \u001b[91m0.83(+3.52%) ▲\u001b[0m\t| LossAB: \u001b[91m0.85(+5.75%) ▲\u001b[0m\t\n",
      "Epoch    39 | LossA: \u001b[91m0.89(+7.27%) ▲\u001b[0m\t| LossAB: \u001b[32m0.79(-7.36%) ▼\u001b[0m\t\n",
      "Epoch    40 | LossA: \u001b[91m0.90(+1.04%) ▲\u001b[0m\t| LossAB: \u001b[91m0.90(+13.68%) ▲\u001b[0m\t\n",
      "Epoch    41 | LossA: \u001b[91m0.93(+2.75%) ▲\u001b[0m\t| LossAB: \u001b[91m0.98(+9.28%) ▲\u001b[0m\t\n",
      "Epoch    42 | LossA: \u001b[91m1.01(+9.35%) ▲\u001b[0m\t| LossAB: \u001b[32m0.87(-12.02%) ▼\u001b[0m\t\n",
      "Epoch    43 | LossA: \u001b[32m0.88(-13.25%) ▼\u001b[0m\t| LossAB: \u001b[32m0.83(-4.38%) ▼\u001b[0m\t\n",
      "Epoch    44 | LossA: \u001b[32m0.83(-5.17%) ▼\u001b[0m\t| LossAB: \u001b[91m0.89(+7.39%) ▲\u001b[0m\t\n",
      "Epoch    45 | LossA: \u001b[91m0.93(+11.16%) ▲\u001b[0m\t| LossAB: \u001b[91m1.01(+13.98%) ▲\u001b[0m\t\n",
      "Epoch    46 | LossA: \u001b[91m0.99(+7.18%) ▲\u001b[0m\t| LossAB: \u001b[32m0.97(-4.19%) ▼\u001b[0m\t\n",
      "Epoch    47 | LossA: \u001b[91m1.00(+0.83%) ▲\u001b[0m\t| LossAB: \u001b[91m0.97(+0.50%) ▲\u001b[0m\t\n",
      "Epoch    48 | LossA: \u001b[32m0.97(-3.56%) ▼\u001b[0m\t| LossAB: \u001b[32m0.93(-5.08%) ▼\u001b[0m\t\n",
      "300/300 [==============================] - 5s 15ms/step\n",
      "Accuracy: 0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "y_test_oh = dense_to_one_hot(y_test, num_clases=4)\n",
    "\n",
    "# visualizing losses and accuracy\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "#Observing the losses but can be commented out as it's not mandatory \n",
    "reporter = lossprettifier.LossPrettifier(show_percentage=True)\n",
    "\n",
    "for i in range(numEpochs-1):\n",
    "    reporter(epoch=i, LossA = train_loss[i], LossAB = val_loss[i])\n",
    "\n",
    "# Model evaluation \n",
    "#score, acc = model.evaluate(x_test, y_test_oh, batch_size=batch_Size)\n",
    "score, acc = model.evaluate(x_test, y_test_oh, batch_size=batch_Size)\n",
    "print(\"Accuracy:\", acc)\n",
    "\n",
    "#if acc>0.675:\n",
    "model.save_weights(modelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.52      0.58       100\n",
      "           1       0.58      0.74      0.65       100\n",
      "           2       0.52      0.49      0.51       100\n",
      "\n",
      "    accuracy                           0.58       300\n",
      "   macro avg       0.59      0.58      0.58       300\n",
      "weighted avg       0.59      0.58      0.58       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_pred = y_pred.reshape(len(y_test), 4)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Writing results on file\n",
    "f = open(resultPath,'a') #create classification report\n",
    "f.write(classification_report(y_test, y_pred))\n",
    "f.write(str(sklm.cohen_kappa_score(y_test, y_pred))+\",\"+str(acc)+\",\"+str(score)+\"\\n\")\n",
    "\n",
    "#Print class-wise classification metrics\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 2)       56        \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 2)       38        \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 2)       0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 4)       76        \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 4)       148       \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 4)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 8)         296       \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 8)         584       \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 8)         584       \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 8)         584       \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 8)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 16)        1168      \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 487,874\n",
      "Trainable params: 487,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.array(['normal', 'COVID19', 'pneumonia']))\n",
    "disp.plot(cmap='Blues') \n",
    "disp.ax_.get_images()[0].set_clim(0, 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wbiad3.6",
   "language": "python",
   "name": "wbiad3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
