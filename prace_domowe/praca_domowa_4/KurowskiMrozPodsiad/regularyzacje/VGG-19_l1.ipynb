{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kurowskik/data_wb_iad/projekt/DeepCOVIDExplainer\n"
     ]
    }
   ],
   "source": [
    "#pip install matplotlib\n",
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "os.chdir(\"/home/kurowskik/data_wb_iad/projekt/DeepCOVIDExplainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('../../data/x_train_undersampled.npy')\n",
    "y_train = np.load('../../data/y_train_undersampled.npy')\n",
    "x_test = np.load('../../data/x_test_undersampled.npy')\n",
    "y_test = np.load('../../data/y_test_undersampled.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5010, 224, 224, 3)\n",
      "(300, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5010,)\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kurowskik/data_wb_iad/projekt/DeepCOVIDExplainer\n"
     ]
    }
   ],
   "source": [
    "#x_train /= 255????\n",
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "print( os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import time\n",
    "import csv\n",
    "from PIL import Image\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from keras import initializers\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential,load_model,Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import *\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras import callbacks\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as sklm\n",
    "from utils import lossprettifier\n",
    "from Classifier import VGG\n",
    "from Classifier.VGG import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducibility\n",
    "np.random.seed(3768)\n",
    "\n",
    "# use this environment flag to change which GPU to use \n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"  # specify which GPU(s) to be used\n",
    "\n",
    "#Get TensorFlow session\n",
    "def get_session(): \n",
    "    config = tf.ConfigProto() \n",
    "    config.gpu_options.allow_growth = True\n",
    "    return tf.Session(config=config) \n",
    "  \n",
    "# One hot encoding of labels \n",
    "def dense_to_one_hot(labels_dense,num_clases=4):\n",
    "    return np.eye(num_clases)[labels_dense]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing training and test sets\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = dense_to_one_hot(y_train,num_clases=4)\n",
    "y_valid= dense_to_one_hot(y_valid,num_clases=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kurowskik/wbiad3.6/lib/python3.6/site-packages/keras_preprocessing/image/image_data_generator.py:349: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, which overrides setting of `featurewise_center`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    }
   ],
   "source": [
    "#Image data generation for the training \n",
    "datagen = ImageDataGenerator(\n",
    "               featurewise_center = False, \n",
    "               samplewise_center = False,  # set each sample mean to 0\n",
    "               featurewise_std_normalization = True,  \n",
    "               samplewise_std_normalization = False)  \n",
    "\n",
    "datagen.fit(x_train) \n",
    "for i in range(len(x_test)):\n",
    "      x_test[i] = datagen.standardize(x_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "32/32 [==============================] - 19s 609ms/step - loss: 1.3611 - acc: 0.3242 - val_loss: 1.3420 - val_acc: 0.3433\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 14s 450ms/step - loss: 1.2225 - acc: 0.4873 - val_loss: 1.1271 - val_acc: 0.6028\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 14s 424ms/step - loss: 1.1075 - acc: 0.5938 - val_loss: 1.0882 - val_acc: 0.6048\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 14s 425ms/step - loss: 1.0685 - acc: 0.6211 - val_loss: 0.9992 - val_acc: 0.6587\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 14s 429ms/step - loss: 1.0665 - acc: 0.5975 - val_loss: 1.0060 - val_acc: 0.6547\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 13s 413ms/step - loss: 1.0336 - acc: 0.6357 - val_loss: 0.9734 - val_acc: 0.6427\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 13s 417ms/step - loss: 1.0220 - acc: 0.6396 - val_loss: 0.8867 - val_acc: 0.7246\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.8948 - acc: 0.7148 - val_loss: 0.8502 - val_acc: 0.7305\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 13s 404ms/step - loss: 0.9171 - acc: 0.7012 - val_loss: 0.9230 - val_acc: 0.7146\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 13s 418ms/step - loss: 0.8947 - acc: 0.7061 - val_loss: 0.9594 - val_acc: 0.6946\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 13s 413ms/step - loss: 0.8716 - acc: 0.7168 - val_loss: 0.8812 - val_acc: 0.7265\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 13s 419ms/step - loss: 0.8398 - acc: 0.7344 - val_loss: 0.8392 - val_acc: 0.7226\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 14s 424ms/step - loss: 0.8413 - acc: 0.7559 - val_loss: 0.8174 - val_acc: 0.7465\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 14s 423ms/step - loss: 0.8343 - acc: 0.7325 - val_loss: 0.7445 - val_acc: 0.7705\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 13s 415ms/step - loss: 0.7923 - acc: 0.7656 - val_loss: 0.7756 - val_acc: 0.7824\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 14s 425ms/step - loss: 0.8196 - acc: 0.7637 - val_loss: 0.8117 - val_acc: 0.7325\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 13s 416ms/step - loss: 0.8150 - acc: 0.7559 - val_loss: 0.7355 - val_acc: 0.7725\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 13s 418ms/step - loss: 0.8219 - acc: 0.7415 - val_loss: 0.8017 - val_acc: 0.7226\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.7546 - acc: 0.7754 - val_loss: 0.7219 - val_acc: 0.7645\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 14s 423ms/step - loss: 0.8117 - acc: 0.7422 - val_loss: 0.9460 - val_acc: 0.6727\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 13s 406ms/step - loss: 0.9548 - acc: 0.6787 - val_loss: 0.8607 - val_acc: 0.7305\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 13s 415ms/step - loss: 0.9085 - acc: 0.6992 - val_loss: 0.8425 - val_acc: 0.7265\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 13s 417ms/step - loss: 0.7963 - acc: 0.7591 - val_loss: 0.8494 - val_acc: 0.7545\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 14s 433ms/step - loss: 0.8533 - acc: 0.7227 - val_loss: 0.7949 - val_acc: 0.7725\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 13s 415ms/step - loss: 0.8656 - acc: 0.7227 - val_loss: 0.8164 - val_acc: 0.7246\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 13s 414ms/step - loss: 0.8081 - acc: 0.7725 - val_loss: 0.7532 - val_acc: 0.7844\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 13s 406ms/step - loss: 0.7106 - acc: 0.8024 - val_loss: 0.7486 - val_acc: 0.7745\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 13s 408ms/step - loss: 0.8003 - acc: 0.7588 - val_loss: 0.7365 - val_acc: 0.7864\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 13s 413ms/step - loss: 0.8097 - acc: 0.7510 - val_loss: 0.7476 - val_acc: 0.7505\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 13s 406ms/step - loss: 0.7638 - acc: 0.7598 - val_loss: 0.7841 - val_acc: 0.7425\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 13s 402ms/step - loss: 0.8286 - acc: 0.7495 - val_loss: 0.8104 - val_acc: 0.7265\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 13s 410ms/step - loss: 0.7630 - acc: 0.7725 - val_loss: 0.7279 - val_acc: 0.7784\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 13s 404ms/step - loss: 0.8046 - acc: 0.7656 - val_loss: 0.8812 - val_acc: 0.7126\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 13s 416ms/step - loss: 0.8455 - acc: 0.7324 - val_loss: 0.7356 - val_acc: 0.7685\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 13s 417ms/step - loss: 0.7651 - acc: 0.7754 - val_loss: 0.7271 - val_acc: 0.7764\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 13s 415ms/step - loss: 0.7847 - acc: 0.7493 - val_loss: 0.8167 - val_acc: 0.7705\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 13s 402ms/step - loss: 0.8696 - acc: 0.7285 - val_loss: 0.9407 - val_acc: 0.6727\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 13s 418ms/step - loss: 0.9942 - acc: 0.6445 - val_loss: 0.9602 - val_acc: 0.6667\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 0.9574 - acc: 0.6621 - val_loss: 0.9582 - val_acc: 0.6766\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 13s 418ms/step - loss: 0.9321 - acc: 0.6778 - val_loss: 0.9631 - val_acc: 0.6607\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 13s 411ms/step - loss: 0.9293 - acc: 0.6963 - val_loss: 0.8535 - val_acc: 0.7345\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 0.8861 - acc: 0.7188 - val_loss: 0.8256 - val_acc: 0.7465\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 13s 417ms/step - loss: 0.9505 - acc: 0.6729 - val_loss: 1.1523 - val_acc: 0.5150\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 14s 425ms/step - loss: 0.9383 - acc: 0.6787 - val_loss: 0.8999 - val_acc: 0.7046\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 13s 407ms/step - loss: 0.8708 - acc: 0.7122 - val_loss: 0.8860 - val_acc: 0.7046\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.8793 - acc: 0.7100 - val_loss: 0.8684 - val_acc: 0.7066\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 13s 419ms/step - loss: 0.9090 - acc: 0.6875 - val_loss: 0.9361 - val_acc: 0.6866\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.9075 - acc: 0.6904 - val_loss: 0.8121 - val_acc: 0.7545\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 13s 415ms/step - loss: 0.8315 - acc: 0.7358 - val_loss: 0.8317 - val_acc: 0.7425\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 13s 415ms/step - loss: 0.8568 - acc: 0.7334 - val_loss: 0.8376 - val_acc: 0.7265\n"
     ]
    }
   ],
   "source": [
    "from Classifier.VGG_with_l1 import *\n",
    "\n",
    "#Defining hyperparameters\n",
    "batch_Size = 32\n",
    "steps_Per_Epoch = 32\n",
    "numEpochs = 50\n",
    "\n",
    "#Instantating VGG19 model\n",
    "model = VGG19_l1((224,224,3),4) #VGG19_dense for revised VGG19, VGG19 for VGG19. Please pay attention to VGG16(), chnage the input shape and class number in VGG.py.\n",
    "\n",
    "#Creating an optimizers\n",
    "adaDelta = keras.optimizers.Adadelta(lr=1.0, rho=0.95)\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.95, nesterov=True)\n",
    "model.compile(optimizer = sgd , loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "#Creating early stopping \n",
    "earlystop = EarlyStopping(monitor = 'val_accuracy', min_delta = 0, patience = 50, verbose = 1, mode = 'auto', restore_best_weights = True)       \n",
    "\n",
    "train_generator = datagen.flow(x_train, y_train, batch_size = batch_Size)\n",
    "validation_generator = datagen.flow(x_valid, y_valid, batch_size = batch_Size)\n",
    "\n",
    "# Model training\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = steps_Per_Epoch,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = 16,\n",
    "    epochs = numEpochs,\n",
    "    shuffle = True, \n",
    "    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = \"VGG19_COVID19_undersampled_l1.h5\"\n",
    "resultPath = 'VGG19_COVID19_undersampled_l1.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     0 | LossA: 1.36(+0.00%) \u001b[0m\t| LossAB: 1.34(+0.00%) \u001b[0m\t\n",
      "Epoch     1 | LossA: \u001b[32m1.22(-10.19%) ▼\u001b[0m\t| LossAB: \u001b[32m1.13(-16.01%) ▼\u001b[0m\t\n",
      "Epoch     2 | LossA: \u001b[32m1.11(-9.41%) ▼\u001b[0m\t| LossAB: \u001b[32m1.09(-3.45%) ▼\u001b[0m\t\n",
      "Epoch     3 | LossA: \u001b[32m1.07(-3.52%) ▼\u001b[0m\t| LossAB: \u001b[32m1.00(-8.18%) ▼\u001b[0m\t\n",
      "Epoch     4 | LossA: \u001b[32m1.07(-0.16%) ▼\u001b[0m\t| LossAB: \u001b[91m1.01(+0.68%) ▲\u001b[0m\t\n",
      "Epoch     5 | LossA: \u001b[32m1.03(-3.11%) ▼\u001b[0m\t| LossAB: \u001b[32m0.97(-3.24%) ▼\u001b[0m\t\n",
      "Epoch     6 | LossA: \u001b[32m1.02(-1.11%) ▼\u001b[0m\t| LossAB: \u001b[32m0.89(-8.91%) ▼\u001b[0m\t\n",
      "Epoch     7 | LossA: \u001b[32m0.89(-12.45%) ▼\u001b[0m\t| LossAB: \u001b[32m0.85(-4.11%) ▼\u001b[0m\t\n",
      "Epoch     8 | LossA: \u001b[91m0.92(+2.46%) ▲\u001b[0m\t| LossAB: \u001b[91m0.92(+8.56%) ▲\u001b[0m\t\n",
      "Epoch     9 | LossA: \u001b[32m0.89(-2.41%) ▼\u001b[0m\t| LossAB: \u001b[91m0.96(+3.95%) ▲\u001b[0m\t\n",
      "Epoch    10 | LossA: \u001b[32m0.87(-2.58%) ▼\u001b[0m\t| LossAB: \u001b[32m0.88(-8.15%) ▼\u001b[0m\t\n",
      "Epoch    11 | LossA: \u001b[32m0.84(-3.65%) ▼\u001b[0m\t| LossAB: \u001b[32m0.84(-4.77%) ▼\u001b[0m\t\n",
      "Epoch    12 | LossA: \u001b[91m0.84(+0.18%) ▲\u001b[0m\t| LossAB: \u001b[32m0.82(-2.60%) ▼\u001b[0m\t\n",
      "Epoch    13 | LossA: \u001b[32m0.83(-0.90%) ▼\u001b[0m\t| LossAB: \u001b[32m0.74(-8.92%) ▼\u001b[0m\t\n",
      "Epoch    14 | LossA: \u001b[32m0.79(-4.97%) ▼\u001b[0m\t| LossAB: \u001b[91m0.78(+4.17%) ▲\u001b[0m\t\n",
      "Epoch    15 | LossA: \u001b[91m0.82(+3.45%) ▲\u001b[0m\t| LossAB: \u001b[91m0.81(+4.66%) ▲\u001b[0m\t\n",
      "Epoch    16 | LossA: \u001b[32m0.81(-0.56%) ▼\u001b[0m\t| LossAB: \u001b[32m0.74(-9.39%) ▼\u001b[0m\t\n",
      "Epoch    17 | LossA: \u001b[91m0.82(+0.90%) ▲\u001b[0m\t| LossAB: \u001b[91m0.80(+9.00%) ▲\u001b[0m\t\n",
      "Epoch    18 | LossA: \u001b[32m0.75(-8.23%) ▼\u001b[0m\t| LossAB: \u001b[32m0.72(-9.95%) ▼\u001b[0m\t\n",
      "Epoch    19 | LossA: \u001b[91m0.81(+7.56%) ▲\u001b[0m\t| LossAB: \u001b[91m0.95(+31.04%) ▲\u001b[0m\t\n",
      "Epoch    20 | LossA: \u001b[91m0.95(+17.64%) ▲\u001b[0m\t| LossAB: \u001b[32m0.86(-9.01%) ▼\u001b[0m\t\n",
      "Epoch    21 | LossA: \u001b[32m0.91(-4.85%) ▼\u001b[0m\t| LossAB: \u001b[32m0.84(-2.12%) ▼\u001b[0m\t\n",
      "Epoch    22 | LossA: \u001b[32m0.80(-12.33%) ▼\u001b[0m\t| LossAB: \u001b[91m0.85(+0.82%) ▲\u001b[0m\t\n",
      "Epoch    23 | LossA: \u001b[91m0.85(+7.14%) ▲\u001b[0m\t| LossAB: \u001b[32m0.79(-6.41%) ▼\u001b[0m\t\n",
      "Epoch    24 | LossA: \u001b[91m0.87(+1.43%) ▲\u001b[0m\t| LossAB: \u001b[91m0.82(+2.71%) ▲\u001b[0m\t\n",
      "Epoch    25 | LossA: \u001b[32m0.81(-6.64%) ▼\u001b[0m\t| LossAB: \u001b[32m0.75(-7.74%) ▼\u001b[0m\t\n",
      "Epoch    26 | LossA: \u001b[32m0.71(-12.02%) ▼\u001b[0m\t| LossAB: \u001b[32m0.75(-0.62%) ▼\u001b[0m\t\n",
      "Epoch    27 | LossA: \u001b[91m0.80(+12.56%) ▲\u001b[0m\t| LossAB: \u001b[32m0.74(-1.61%) ▼\u001b[0m\t\n",
      "Epoch    28 | LossA: \u001b[91m0.81(+1.18%) ▲\u001b[0m\t| LossAB: \u001b[91m0.75(+1.51%) ▲\u001b[0m\t\n",
      "Epoch    29 | LossA: \u001b[32m0.76(-5.67%) ▼\u001b[0m\t| LossAB: \u001b[91m0.78(+4.89%) ▲\u001b[0m\t\n",
      "Epoch    30 | LossA: \u001b[91m0.83(+8.56%) ▲\u001b[0m\t| LossAB: \u001b[91m0.81(+3.35%) ▲\u001b[0m\t\n",
      "Epoch    31 | LossA: \u001b[32m0.76(-7.98%) ▼\u001b[0m\t| LossAB: \u001b[32m0.73(-10.17%) ▼\u001b[0m\t\n",
      "Epoch    32 | LossA: \u001b[91m0.80(+5.44%) ▲\u001b[0m\t| LossAB: \u001b[91m0.88(+21.06%) ▲\u001b[0m\t\n",
      "Epoch    33 | LossA: \u001b[91m0.85(+5.08%) ▲\u001b[0m\t| LossAB: \u001b[32m0.74(-16.53%) ▼\u001b[0m\t\n",
      "Epoch    34 | LossA: \u001b[32m0.77(-9.51%) ▼\u001b[0m\t| LossAB: \u001b[32m0.73(-1.15%) ▼\u001b[0m\t\n",
      "Epoch    35 | LossA: \u001b[91m0.78(+2.59%) ▲\u001b[0m\t| LossAB: \u001b[91m0.82(+12.31%) ▲\u001b[0m\t\n",
      "Epoch    36 | LossA: \u001b[91m0.87(+10.80%) ▲\u001b[0m\t| LossAB: \u001b[91m0.94(+15.19%) ▲\u001b[0m\t\n",
      "Epoch    37 | LossA: \u001b[91m0.99(+14.33%) ▲\u001b[0m\t| LossAB: \u001b[91m0.96(+2.07%) ▲\u001b[0m\t\n",
      "Epoch    38 | LossA: \u001b[32m0.96(-3.70%) ▼\u001b[0m\t| LossAB: \u001b[32m0.96(-0.21%) ▼\u001b[0m\t\n",
      "Epoch    39 | LossA: \u001b[32m0.93(-2.63%) ▼\u001b[0m\t| LossAB: \u001b[91m0.96(+0.51%) ▲\u001b[0m\t\n",
      "Epoch    40 | LossA: \u001b[32m0.93(-0.32%) ▼\u001b[0m\t| LossAB: \u001b[32m0.85(-11.38%) ▼\u001b[0m\t\n",
      "Epoch    41 | LossA: \u001b[32m0.89(-4.65%) ▼\u001b[0m\t| LossAB: \u001b[32m0.83(-3.27%) ▼\u001b[0m\t\n",
      "Epoch    42 | LossA: \u001b[91m0.95(+7.27%) ▲\u001b[0m\t| LossAB: \u001b[91m1.15(+39.57%) ▲\u001b[0m\t\n",
      "Epoch    43 | LossA: \u001b[32m0.94(-1.28%) ▼\u001b[0m\t| LossAB: \u001b[32m0.90(-21.90%) ▼\u001b[0m\t\n",
      "Epoch    44 | LossA: \u001b[32m0.87(-7.19%) ▼\u001b[0m\t| LossAB: \u001b[32m0.89(-1.55%) ▼\u001b[0m\t\n",
      "Epoch    45 | LossA: \u001b[91m0.88(+0.97%) ▲\u001b[0m\t| LossAB: \u001b[32m0.87(-1.99%) ▼\u001b[0m\t\n",
      "Epoch    46 | LossA: \u001b[91m0.91(+3.38%) ▲\u001b[0m\t| LossAB: \u001b[91m0.94(+7.79%) ▲\u001b[0m\t\n",
      "Epoch    47 | LossA: \u001b[32m0.91(-0.17%) ▼\u001b[0m\t| LossAB: \u001b[32m0.81(-13.24%) ▼\u001b[0m\t\n",
      "Epoch    48 | LossA: \u001b[32m0.83(-8.32%) ▼\u001b[0m\t| LossAB: \u001b[91m0.83(+2.41%) ▲\u001b[0m\t\n",
      "300/300 [==============================] - 3s 10ms/step\n",
      "Accuracy: 0.7166666674613953\n"
     ]
    }
   ],
   "source": [
    "y_test_oh = dense_to_one_hot(y_test, num_clases=4)\n",
    "\n",
    "# visualizing losses and accuracy\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "#Observing the losses but can be commented out as it's not mandatory \n",
    "reporter = lossprettifier.LossPrettifier(show_percentage=True)\n",
    "\n",
    "for i in range(numEpochs-1):\n",
    "    reporter(epoch=i, LossA = train_loss[i], LossAB = val_loss[i])\n",
    "\n",
    "# Model evaluation \n",
    "#score, acc = model.evaluate(x_test, y_test_oh, batch_size=batch_Size)\n",
    "score, acc = model.evaluate(x_test, y_test_oh, batch_size=batch_Size)\n",
    "print(\"Accuracy:\", acc)\n",
    "\n",
    "#if acc>0.675:\n",
    "model.save_weights(modelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.78      0.74       100\n",
      "           1       0.71      0.71      0.71       100\n",
      "           2       0.73      0.66      0.69       100\n",
      "\n",
      "    accuracy                           0.72       300\n",
      "   macro avg       0.72      0.72      0.72       300\n",
      "weighted avg       0.72      0.72      0.72       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_pred = y_pred.reshape(len(y_test), 4)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Writing results on file\n",
    "f = open(resultPath,'a') #create classification report\n",
    "f.write(classification_report(y_test, y_pred))\n",
    "f.write(str(sklm.cohen_kappa_score(y_test, y_pred))+\",\"+str(acc)+\",\"+str(score)+\"\\n\")\n",
    "\n",
    "#Print class-wise classification metrics\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 2)       56        \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 2)       38        \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 2)       0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 4)       76        \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 4)       148       \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 4)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 8)         296       \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 8)         584       \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 8)         584       \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 8)         584       \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 8)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 16)        1168      \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 487,874\n",
      "Trainable params: 487,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEKCAYAAAA7LB+5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAl9klEQVR4nO3dd5xU1fnH8c93KdI72ECxAEaKBJHYYoi9Ro1JbDFY8jPGmhiNLYnGFksSuzHERqJii8YSoyYqtthABKRFsSsKKCAinef3x72rw7rsDMvszh3m++Y1r71z5s65z8wOz54595xzFRGYmVl2VZU6ADMzq5sTtZlZxjlRm5llnBO1mVnGOVGbmWWcE7WZWcY5UZuZrSZJN0qaIenVnLJOkv4t6bX0Z8e0XJKulPS6pPGSBuWr34nazGz13QzsXqPsdOCxiOgFPJbeB9gD6JXejgb+lK9yJ2ozs9UUEU8Bn9Qo3hcYkW6PAPbLKf9rJJ4HOkhat676mxYxVgOqWraLpm27lTqMzOq9brtSh5B5TZuo1CFk3rixL8+KiK6rU0eTdhtGLF2Qd79YMHMisDCnaHhEDC/gEGtHxPR0+0Ng7XR7feDdnP3eS8umsxJO1EXWtG03un7v0lKHkVl3/3rXUoeQeV3arlXqEDKva9tmb69uHbF0AWv1+UHe/Ra+cs3CiBi8WseKCEn1Xq/DXR9mVqEEqsp/q7+Pqrs00p8z0vL3gR45+3VPy1bKidrMKpOAqib5b/V3PzAs3R4G3JdT/qN09MfWwNycLpJauevDzCqXinM+QNJIYCjQRdJ7wNnARcCdko4C3gaq+1keAvYEXgc+B47IV78TtZlVKK1u18YXIuLglTy0Uy37BnDcqtTvRG1mlatILeqG5kRtZpVJFK1F3dCcqM2sQsktajOzzFu9UR2NxonazCpU8U4mNjQnajOrTMJdH2ZmmecWtZlZlrnrw8ws2wQ08clEM7Nscx+1mVmWuevDzCz73KI2M8s4t6jNzDJMnkJuZpZ9nkJuZpZlPploZpZ97vowM8swr0dtZpZ17vowM8s+n0w0M8s491GbmWWY3PVhZpZ9blGbmWWbnKjNzLIruRKXE7WZWXZJqMqJ2hrZRt3acOXhW31xv0eX1lz+0GReeG0W5x04kLWaVrFsefCbO8cx/p3ZJYy0dM657C6eenEynTq04e4/nfxF+cj7n+XOB5+jqkp8c6uv8bOj9ixhlNkxd97n/PLiO5j65nQk+P3pB7Nlv41KHVbRuEW9BpL0FjA4ImaVOpbavDnjM/a55AkAqgT/PW8PHh33ARce/HWu+tcUnpz8EUM3X5vT9u3LoVc9U+JoS2OfnbfkwH225dd/uOOLspfGTWPU85O445qf0bxZUz6Z81kJI8yWc668l6Hf2Iw/n38Ei5csZcHCxaUOqajKJVGXx9iUIpBUUX+Utu3TjXdmzeeD2QuIgDYtkpfftkUzZsxdWOLoSmfL/hvTvm3LFcru+udzHPH9oTRvlrxHnTq0KUVomfPpZwt4Ydw0Dtp7awCaN2tK+7atShxVcUnKe8uCskpeknoC/wKeAbYF3gf2BfoA1wGtgGnAkRExW9Io4BVge2CkpH2AscA3gdbAj4AzgP7AHRHxq/Q4/wB6AC2AKyJieKO8wCLae1B3HhjzHgDn3zOBm3+6LWfs1w9JfP+yJ0scXba8/cEsxk58k2tGPELz5k05+cd70bd3j1KHVXLvTv+YTh3acPKFtzF52gf0792D3560P61arlXq0IpD6a0MlGOLuhdwTUT0BeYABwB/BU6LiAHABODsnP2bR8TgiPhDen9xRAwmSez3AccB/YDDJXVO9zkyIrYEBgMn5pSXhWZNxE791uGhV94H4NDtN+L8eyew/dmPcMG9E7jokEEljjBbli1bztx5C/jrZcfx86P24pe/u5WIKHVYJbd02XJe/d97/Gi/7Xj4xlNp1bI519z6WKnDKhqRvzWdlRZ1OSbqNyPilXR7DLAJ0CEiqpuJI4Adcva/gxXdn/6cAEyMiOkRsQh4g6QVDUlyHgc8n5b1qisgSUdLGi1p9PIFn9bnNRXVtzZfh4nvzeHjeYsA+O6QDXhk3AcAPDT2fQZs2LGU4WXO2l3as9O2ybeNfn16UCUx+9P5pQ6r5Nbt2oF1u7bn6317ArDn0C14dep7pQ2qyKqqqvLesiAbUayaRTnby4AOefav+T+u+vnLa9S1HGgqaSiwM7BNRGxB0lXSoq4DRMTwtNU+uKpluzzhNLx9cro9AD6au5BvbNoFgG17d+XtmT5Zlmvo1n15afw0AN5+byZLli6jY7vWJY6q9Lp1bse63Toy7Z2PAHh2zP/o1XPtEkdVXOXSoi6rPuqVmAvMlvTNiHgaOAxYnU7Y9sDsiPhc0mbA1sUIsrG0bN6E7Tbrxll3jP2i7Mzbx/KbA/rTpKqKRUuWcdbtr5QuwBI7/eLbGDP+DeZ8Op/dDruAY364C/vtOphzLr+b7/30jzRr2oRzT/5BZv6Dltp5P/suJ5x7C0uWLGWD9TrzhzMPKXVIxVNGfdRrQqIGGAZcJ6kVSRfGEatR18PAMZImA1NJuj/KxoLFyxh8xj9XKBvzxsfse+mo0gSUMRedVnuiueDUgxo5kvLQt1d3Hrr+F6UOo8GUyx/kskrUEfEWyYm/6vu/z3n4Ky3fiBi6svsRMQoYtZJ991jJ8XuuQrhmlmHVJxOLUpf0c+DHQJCc/zoCWBe4HehMcj7tsIio10D0cuyjNjMrClUp7y1vHdL6wIkkk+H6AU2Ag4CLgcsiYlNgNnBUfeN0ojazyqSinkxsCrRMJ9a1AqYDOwJ3p4+PAParb6hO1GZWsQpM1F2qh9+mt6Nz64iI94HfA++QJOi5JF0dcyJiabrbe8D69Y2zrPqozcyKqcAW86x0ktzK6uhIMkN6I5JJeHcBuxcjvmpO1GZWkYp4MnFnkol4MwEk3QNsB3SQ1DRtVXcnWfKiXtz1YWaVSwXc8nsH2FpSKyWZfydgEvAE8L10n2EkS1bUixO1mVUmFWcKeUS8QHLS8GWSoXlVwHDgNOBkSa+TDNG7ob6huuvDzCpWscZRR8TZrLgYHCST74YUo34najOrXOUxMdGJ2swql6eQm5llWJZWx8vHidrMKpYTtZlZxhWylkcWOFGbWcVyi9rMLMvkRG1mlmkCyiRPO1GbWaXyqA8zs8yr8slEM7MMk7s+zMwyTbhFbWaWeW5Rm5llnE8mmpllmfuozcyyTaigCwNkgRO1mVUst6jNzDLOfdRmZlnmPmozs2xL1vooj0ztRG1mFatM8rQTtZlVLs9MNDPLMq9HXbk2W689D563R6nDyKw9L3u61CFk3u3HbFPqECqC16M2M8s8r0dtZpZ5ZZKnnajNrELJJxPNzDLN46jNzMqAE7WZWcaVSZ52ojazyuUWtZlZlnlRJjOzbEsuHFAemdqJ2swqVlWZNKnL4zo0ZmYNQMp/K6wedZB0t6QpkiZL2kZSJ0n/lvRa+rNjfeN0ojaziqR0UaZ8twJdATwcEZsBWwCTgdOBxyKiF/BYer9enKjNrGJVKf8tH0ntgR2AGwAiYnFEzAH2BUaku40A9qtvnCvto5Z0FRArezwiTqzvQc3MsqDAk4ldJI3OuT88Iobn3N8ImAncJGkLYAxwErB2RExP9/kQWLu+cdZ1MnF0HY+ZmZU1kYz8KMCsiBhcx+NNgUHACRHxgqQrqNHNEREhaaUN33xWmqgjYkTufUmtIuLz+h7IzCxrijQ67z3gvYh4Ib1/N0mi/kjSuhExXdK6wIz6HiBvH3V69nISMCW9v4Wka+t7QDOzTCjgRGIhJxMj4kPgXUl90qKdgEnA/cCwtGwYcF99Qy1kHPXlwG7pQYmIcZJ2qO8BzcyyoojDqE8AbpXUHHgDOIKkIXynpKOAt4Ef1Lfygia8RMS7Nf6yLKvvAc3MskAUb8JLRLwC1NaPvVMx6i8kUb8raVsgJDUjOZs5uRgHNzMrpXKZQl7IOOpjgOOA9YEPgIHpfTOzslXIrMSszDDP26KOiFnAoY0Qi5lZo1pj1vqQtLGkByTNlDRD0n2SNm6M4MzMGpIKuGVBIV0ftwF3AusC6wF3ASMbMigzs8ZQxLU+GlQhibpVRPwtIpamt1uAFg0dmJlZQ0pGfaz+Wh+Noa61Pjqlm/+SdDpwO8naHwcCDzVCbGZmDUdrxoUDxpAk5upX8pOcxwI4o6GCMjNrDFnp2sinrrU+NmrMQMzMGlN110c5KGhmoqR+wObk9E1HxF8bKigzs8ZQ9i3qapLOBoaSJOqHgD2AZwAnajMra+WRpgsb9fE9kvnqH0bEESSXmWnfoFGZmTUwCZpUKe8tCwrp+lgQEcslLZXUjmRN1R4NHJfVwxmX3sGoFybRuUMbHrz+VAD+9eQ4rv7ro0x7ZwZ3XX0i/ftU7q9uw86tuPD7A764v37Hlvz5iWnM+HQhRw/dhI26tmbYX15k8gefljDK0jr3irt45qUpdGzfhjuu+TkAU9/4gIuuvZdFi5fStEkVp/10P/r2XjM+R+XS9VFIi3q0pA7AX0hGgrwMPFfsQCStI+l2SdMkjZH0kKTekvpKelzS1PRqvr9W4luSnqtRR1NJH0laT9LNkr6Xlo9Knz8+vUrw1elrqn7ejemsy1dr1LeFpOckTUhnZ7Yr9usupu/uNpjrf/d/K5T17rkOV50zjK36+9zw2x9/zqHXPc+h1z3PYX9+noVLlvHE5BlMmzGfX94xjrFvzy51iCW3905bcuU5R65QdtVN/+LHB+3MbVeexE8O3YUrb1pzRueWy1ofeRN1RBwbEXMi4jpgF2BY2gVSNEr+rN0LjIqITSJiS5Lhf2uTrIN9UUT0Iel22RY4Fnga6C5pw5yqdgYmRsQHtRzm0IgYAAwAFrHiIt43A7vX8pzrgdMjon8a36n1f5UNb6sBm9C+basVyjbZcG027tGtRBFl11Ybd+L9Txbw4dyFvDVrPm9/7IsXAQzqtzHt2rZcoUyC+QsWAvDZ/IV07ZTp9krBhKhS/lsWrDRRSxpU8wZ0Apqm28X0bWBJ+scASC5QAPQGno2IR9Oyz4HjSZLncpKp7Qfl1HMQeaa3R8Ri4JfABumFKImIp4BPatm9N/BUuv1v4IBVf2mWRbv1W4dHXv2w1GGUhZP/bx+uvPEh9jrid1xx40McN6y2Nk0ZWkNWz/tDHY8FsGMR4+hH0q1SU9+a5RExTVKbtBtiJEmXzMWS1gL2BE7Od7CIWCZpHLAZMK6OXSeSXPL9H8D3WUnfvKSjgaMB1u++ZvTdrcmaNhE79OnK1f95vdShlIW/P/Q8J/94b3bcrj//fno85135d649/8elDqsoyr6POiK+XcetmEm63iJiNNAmvVbZHsALEVFby7g2hfyGjgSOlTQGaAssXkkcwyNicEQM7tS5a4GHt1LZbtMuTJk+j0/m1/rrtBoefHwM3962HwA7b9+fSf97t8QRFYeAJlLeWxYUcjKxMUwEtqylfFLN8nSJ1c8iovrU/EiSLo+83R45dTQB+pPnSjURMSUidk37zEcC0wqp37Jtt/7r8MgEd3sUqmundrz86hsAvDR+Gj3W61LiiIqn7BdlamSPAxdKOjoihgNIGgBMBc6UtHNE/EdSS+BK4JKc544kOeHYHjgq34HSy4ldALwbEePz7NstImZIqgJ+BVxX1/6ldvIFt/DiuGnMnjufHQ46jxOG7UqHtq047+p/8Mncz/jJWTfwtU3W44aLjy51qCXTolkVQzbuxAUPfPk3euhmXTl1z83o2Ko5lx8ykP99OI8TbhlbwihL56xLRzJmwhvM+XQ+ex1+IUcfsgtnHX8Af/jLAyxbtozmzZtx5vH7lzrMoslKIs4nE4k6IkLS/sDlkk4DFgJvAT8j6SO+StI1QBPgb8DVOc+dLGk+MCYi5tdxmFslLQLWAv6T1guApJEksy+7SHoPODsibgAOllR92bF7gJuK8HIbzB/P+mGt5bts37+RI8muhUuWs/MlT65QNmrKTEZNmVmiiLLlglMPrrX8b5ef0MiRNLzkZGF5ZOpCppCL5FJcG0fEuZI2ANaJiBeLGUg6pG5ll1Mfmue5A2spOzxnO9/za/10RsQVwBV1PdfMyle5tKgL6aO+FtgGqE5m84BrGiwiM7NGsiYMz6v2jYgYJGksQETMltS8geMyM2tQAppmJRPnUUiiXpKOkggASV2B5Q0alZlZIyiTPF1Qor6SZPp0N0kXkKym96sGjcrMrIEpQ1PE88mbqCPi1nTCx04k3xb2i4g6xx+bmZWDMsnTBY362AD4HHggtywi3mnIwMzMGlq5jPoopOvjn3x5kdsWwEYkE1H6NmBcZmYNSpCZCwPkU0jXxwqzJdKV845tsIjMzBpDhqaI57PKMxMj4mVJ32iIYMzMGpPK5KqJhfRR5y4bWgUMAmpbmN/MrGyINatF3TZneylJn/XfGyYcM7PGs0Yk6nSiS9uIOKWR4jEzazRlvyiTpKYRsVTSdo0ZkJlZY5CgSVZW5M+jrhb1iyT90a9Iuh+4C/hiGdGIuKeBYzMza1DFnJmY9kCMBt6PiL0lbQTcDnQmuaTgYek1W1c9zgL2aQF8THKNxL2BfdKfZmZlq/pkYhGv8HISK1416mLgsojYFJhNARc2WZm6EnW3dMTHq8CE9OfE9Oer9T2gmVlWFGuZU0ndgb2A69P7Imnc3p3uMgLYr75x1tX10QRoQ+0XgY36HtDMLBtEVWHjqLtIGp1zf3j1JQNzXA78ki9HyXUG5kTE0vT+e8D69Y20rkQ9PSLOrW/FZmZZJgpuMc+KiMErrUfaG5gREWMkDS1KcDXUlajLY9yKmVl9CJoWZyD1dsB3JO1Jck6vHckl/DpUj54DugPv1/cAdfVR71TfSs3Msq66Rb26fdQRcUZEdI+InsBBwOMRcSjwBMn6/QDDgPvqG+tKE3VEfFLfSs3MykFVevGAum6r4TTgZEmvk/RZ31DfilZ5USYzszVFsScmRsQoYFS6/QYwpBj1OlGbWUUShU0kyQInajOrTCruzMSG5ERtZhUpmZnoRG1mlmnlkaadqM2sgpVJg9qJ2swqlcp/PWozszWZR32YmZUBn0ysUEuXL+fjz+q1NnhFuP+k7UsdQub98KaXSh1CZdAacCkuM7M1mbs+zMzKgFvUZmYZVx5p2onazCqUgCZuUZuZZVuZ5GknajOrVEJl0vnhRG1mFcstajOzDEuG55VHpnaiNrPKVOA1EbPAidrMKpankJuZZVhy4YBSR1EYJ2ozq1ge9WFmlnFl0vPhRG1mlcstajOzDHMftZlZ1kke9WFmlnXlkaadqM2sQiVdH+WRqp2ozaxilUeadqI2s0pWJpnaidrMKpa7PszMMq480rQTtZlVsjLJ1E7UZlaRhGcmmpllWxmtR11V6gDMzEpFBdzy1iH1kPSEpEmSJko6KS3vJOnfkl5Lf3asb5xO1GZWoYSU/1aApcAvImJzYGvgOEmbA6cDj0VEL+Cx9H69OFGbWcWS8t/yiYjpEfFyuj0PmAysD+wLjEh3GwHsV9843UdtZhWp0K4NoIuk0Tn3h0fE8FrrlHoCXwdeANaOiOnpQx8Ca9c3VidqM6tchWXqWRExOG9VUhvg78DPIuLT3G6TiAhJUd8w3fVhZhVLBfwrqB6pGUmSvjUi7kmLP5K0bvr4usCM+sbpFvUa5KOZczjvirv4ZM5nSOI7u27Fgftsx+PPTuCG2x/jrfdmcv2lP+Vrm3Yvdagl86s/3MmTz0+iU4c23PeXUwC48uaHeeK5iUiic4c2XHDqgXTr3L7EkZZO67WacMouvdmoS2si4NJHpzJp+jz2H7ge+w5cj+XLg+ff/IThT79Z6lBXWzGG5ylpOt8ATI6IP+Y8dD8wDLgo/XlffY/hRF0LSQ8Bh0TEnFLHsiqaNKnihCP2pM8m6zN/wSKO/MXVDBm4KRtvsDYXnn4ol1z7j1KHWHL77TKYQ76zLWdccvsXZUd+fygnHr47ALfc+wx/uuU/nH3SAaUKseSOH7opL701m98+OJmmVWKtZlUM7NGebTfpzP/9bQxLlgUdWjYrdZirr3jjqLcDDgMmSHolLTuTJEHfKeko4G3gB/U9gBN1LSJiz1LHUB9dOrWjS6d2ALRuuRYbdu/GzI8/ZcjAXiWOLDsGD9iY9z/8ZIWyNq1bfLG9YOHispkE0RBaN2/CgO7tufiRqQAsXR4sXbSM7wxYj5EvvcuSZUk365wFS0oZZtEUY2ZiRDzDynu7d1rtA9CAfdSSekqaIulWSZMl3S2plaS3JP1W0suSJkjaLN2/taQbJb0oaaykfdPywyVdnVPvg5KGptufSbo0HWT+H0lDJI2S9Iak76T7tJB0U3qssZK+nVPvPZIeTgekX5JzjLckdUm3/yFpTHqMoxvq/Sq26R/N5rU3PqBv7x6lDqUsXHHTv9jpkPN58PGXOf5Hu5U6nJJZp30L5i5YzC93682ffziIX+zSixZNq+jesSX912/PNQcP5LIfDKDP2m1KHepqE8UZntcYGvpkYh/g2oj4GvApcGxaPisiBgF/Ak5Jy84CHo+IIcC3gUsltc5Tf+v0OX2BecD5wC7A/sC56T7HkZx07Q8cDIyQVN2EGggcCPQHDpRUW1Y7MiK2BAYDJ0rqXPCrL5HPFyzizItv5aSj9qJ1qxb5n2CcdMQePHbbr9h7x0Hcdv+zpQ6nZJpUiV7d2nL/uOn85JaXWbhkOQcP6UGTKtGuRVOOG/kKf37qTX6z9+alDrUoijEzsTE0dKJ+NyKqP/W3ANun29VnRccAPdPtXYHT0z6eUUALYIM89S8GHk63JwBPRsSSdLu63u3TYxMRU0j6inqnjz0WEXMjYiEwCdiwlmOcKGkc8DzQA/hKP4KkoyWNljR69icf5wm5YS1duowzL76NXb81kKHb9CtpLOVor52+zr+fnlDqMEpm5rxFzJy3iCkfzgPgqddm0qtbG2Z+toinX58FwJQP5xERtF9D+qnLIVM3dKKuOW6w+v6i9OcyvuwnF3BARAxMbxtExGSS6Zm5ceY2EZdERHWdy6vrjYjlFNb/vihnOzeWJKCki2VnYJuI2AIYW+P4pMcbHhGDI2Jwx06la3BHBBdefQ89u3fl4H23z/8EA+Dt92d+sf3EfyeyUY9uJYymtGZ/voQZ8xbRo2NLAAZt0JG3P/mcZ1//mIE9OgDQvUNLmjapYu4a0E9dlV6JvK5bFjT0ycQNJG0TEc8BhwDPkMzaqc0jwAmSTkgHh389IsYCbwHHSqoimZY5ZBVjeBo4FHhcUm+SVvpUYFABz20PzI6Iz9O+9K1X8diNavzkt3l41Fg22XAdhv3sKgB+8sNdWbJ0KX/8ywPMmTufU84bQa+N1uPyc44ocbSlccqFt/LS+GnMmTufHQ85n+MO25WnXprMW+/OpKpKrNutY0WP+AC46onXOXOPzWjaREyfu5BLHvkfC5cs49TdenPDj7Zk6bLlXPzw1FKHWRTZSMP5NXSinkqyQMmNJF0LfwJOWMm+5wGXA+PTpPwmsDfwbLo9iWQO/curGMO1wJ8kTSBpnR8eEYsKXGzlYeAYSZPT1/L8Kh67UW2xeU/++48La33sW1v3beRosun3Zx76lbID9ljVv/1rtmkz5/PT28Z+pfx3/1ozkvMKyiRTN3SiXhoRP6xR1rN6IyJGA0PT7QXAT2pWkHZtfPV/V/JYm5ztc2p7LO1//krzMSJuBm7Oub93znbPnF33qO3YZlbefOEAM7Osy9Dwu3waLFFHxFuAhx2YWWaVSZ52i9rMKlXBFwYoOSdqM6tYZZKnnajNrDJlaD5LXk7UZla5yiRTO1GbWcXy8Dwzs4xzH7WZWZYJqpyozcyyrjwytRO1mVWk6gsHlAMnajOrWGWSp52ozaxyuUVtZpZxnkJuZpZx5ZGmnajNrEJl6Srj+ThRm1nF8sxEM7OsK4887URtZpWrTPK0E7WZVSpRVSad1E7UZlaRymlmYlWpAzAzs7q5RW1mFatcWtRO1GZWsTw8z8wsyzzhxcws28rpZKITtZlVLHd9mJllXLm0qD08z8wqlgq4FVSPtLukqZJel3R6seN0ojazylWETC2pCXANsAewOXCwpM2LGaYTtZlVJAFVUt5bAYYAr0fEGxGxGLgd2LeosUZEMeureJJmAm+XOo4augCzSh1Ehvn9yS9r79GGEdF1dSqQ9DDJ68qnBbAw5/7wiBieU8/3gN0j4sfp/cOAb0TE8asTXy6fTCyy1f3wNARJoyNicKnjyCq/P/mtie9RROxe6hgK5a4PM7PV8z7QI+d+97SsaJyozcxWz0tAL0kbSWoOHATcX8wDuOujMgzPv0tF8/uTn9+jlYiIpZKOBx4BmgA3RsTEYh7DJxPNzDLOXR9mZhnnRG1mlnFO1FYnSW9JKmSsaaOQtI6k2yVNkzRG0kOSekvqK+nxdBrva5J+rcS3JD1Xo46mkj6StJ6km9NxsEgalT5/vKQpkq6W1CHneTdKmiHp1Rr1bSHpOUkTJD0gqV2jvBllKv2ddSh1HOXEiXoNJmmNOlksScC9wKiI2CQitgTOANYmOct+UUT0AbYAtgWOBZ4GukvaMKeqnYGJEfFBLYc5NCIGAAOARcB9OY/dDNQ29vZ64PSI6J/Gd2r9X+WaLyL2jIg5pY6jnDhRZ5yknpImS/qLpImSHpXUUtJASc+nrb97JXVM9x8l6XJJo4GT0vuXSRqd1rOVpHvSVuf5Ocf5R9pCnSjp6JK94Lp9G1gSEddVF0TEOKA38GxEPJqWfQ4cT5I8lwN3kgyZqnYQMLKuA6VTgX8JbCBpi7TsKeCTWnbvDTyVbv8bOGDVX9qqST8XUyTdmv5e75bUKv0G9FtJL6ct/M3S/Vun3whelDRW0r5p+eGSrs6p90FJQ9PtzyRdmn4m/iNpSPp5ekPSd9J9Wki6KT3WWEnfzqn3HkkPp5+1S3KO8cW3tDL53JWcE3V56AVcExF9gTkkieCvwGlp628CcHbO/s0jYnBE/CG9vzidVXYdSQvxOKAfcLikzuk+R6Yt1MHAiTnlWdIPGFNLed+a5RExDWiTdkOMJE3UktYC9gT+nu9gEbEMGAdslmfXiXy5tsP3WXHyQ0PqA1wbEV8DPiX5BgEwKyIGAX8CTknLzgIej4ghJH/wLpXUOk/9rdPn9AXmAecDuwD7A+em+xwHRPpt4mBghKQW6WMDgQOB/sCBkmp7X8rhc1dyTtTl4c2IeCXdHgNsAnSIiCfTshHADjn731Hj+dWD7yeQfOWfHhGLgDf4MqmcKGkc8Hxa1qu4L6F0ImI0SdLuQ7LC2QsRUVvLuDaFrMpzJHCspDFAW2Bx/SJdZe9GxLPp9i3A9un2PenPMUDPdHtX4HRJrwCjSNav2CBP/YuBh9PtCcCTEbEk3a6ud/v02ETEFJJ1bnqnjz0WEXMjYiEwCcjtfqq2xn7uimmN6sNcgy3K2V4GdMiz//yVPH95jbqWA03Tr7o7A9tExOeSRpH8R86aicD3aimfxIp/qJC0MfBZRHyaFlW3qr9Gnm6PnDqakLQGJ9e1X5qgdk2f0xvYq5D6i6DmJIjq+9W/42V8+X9cwAERMTX3CZK2ZMUGW+7vfUl8OdHii89ORCwv8PxHzc/tCs8po89dyblFXZ7mArMlfTO9fxjwZB3759MemJ3+Z9kM2Hp1A2wgjwNr5fZlShoATAW2l7RzWtYSuBK4JOe5I4EfAjuy4gnCWklqBvyOpNU6Ps++3dKfVcCvSLqYGsMGkrZJtw8Bnqlj30eAE9ITskj6elr+FjBQUlXaNTFkFWN4Gjg0rbM3SSt9ap3P+FK5fO5Kzom6fA0j6WccT9IXeG7du9fpYZKW9WTgIpKvoZmTtu72B3ZWMjxvIkky/ZCkj/hXkqaSfDV/Cbg657mTSb5pPB4RNb9x5Lo1fU9fJemj/WJdYUkjgeeAPpLek3RU+tDBkv4HTAE+AG4qygvObypwXPp760jSJ70y5wHNgPHp+3ZeWv4s8CbJt5IrgZdXMYZrgSpJE0i63A5Pu9UKURafuyzwFHKzMiSpJ/BgRPQrdSzW8NyiNjPLOLeozcwyzi1qM7OMc6I2M8s4J2ozs4xzorZGJ2mZpFckvSrpLkmtVqOu3NXvrpe0eR37DpW0bT2OUesKgisrr7HPZ6t4rHMknZJ/T6skTtRWCgsiYmA6tGwxcEzugwXOevuKiPhxREyqY5ehJKvqmZUVJ2ortaeBTdPW7tOS7gcmSWqSrtz2kpIVAn8CyVKnStaJnirpP0C36orSld0Gp9u7pyvIjZP0WDru+Bjg52lr/puSukr6e3qMlyRtlz63s5JVCidKup4C1vuoaxU4JasXTkzj6JqWbZKuLDcmfd35Fn6yCua1Pqxk0pbzHny58M8goF9EvJkmu7kRsVW64t2zkh4Fvk6yatzmJOtQTwJurFFvV+AvwA5pXZ0i4hNJ15Gs//H7dL/bgMsi4hlJG5BMs/4ayUqEz0TEuZL2Ao4ivyPTY7QEXpL094j4mGR24+iI+Lmk36R1H09ysdhjIuI1Sd8gmeG3Yz3eRqsATtRWCi3TVdwgaVHfQNIl8WJEvJmW7woMqO5/JlkXohfJ4ksj0yVIP5D0eC31bw08VV1XHSvl7Qxsni5/AdBOUpv0GN9Nn/tPSbMLeE0nSto/3a5eBe5jksWMqlczvAW4Jz3GtsBdOcdeq4BjWIVyorZSWBARA3ML0oSVuwaHgBMi4pEa++1ZxDiqgK3TZThrxlKwVVwFLtLjzqn5HpitjPuoLaseAX6armKHkusitia5ksqBaR/2uiSL4Nf0PLCDpI3S53ZKy+eRrBdd7VHghOo7kgamm0+RrEaHpD1IFjyqS12rwFXx5dKsh5B0qXwKvCnp++kxpPQqMma1caK2rLqepP/5ZSUXk/0zyTfAe4HX0sf+SrKa3QoiYiZwNEk3wzi+7Hp4ANi/+mQicCIwOD1ZOYkvR5/8liTRTyTpAnknT6x1rQI3HxiSvoYd+XKVw0OBo9L4cq8QY/YVXuvDzCzj3KI2M8s4J2ozs4xzojYzyzgnajOzjHOiNjPLOCdqM7OMc6I2M8u4/wefGr4ZXqnL8AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.array(['normal', 'COVID19', 'pneumonia']))\n",
    "disp.plot(cmap='Blues') \n",
    "disp.ax_.get_images()[0].set_clim(0, 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wbiad3.6",
   "language": "python",
   "name": "wbiad3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
