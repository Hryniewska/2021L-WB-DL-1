{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('data/x_train_undersampled.npy')\n",
    "y_train = np.load('data/y_train_undersampled.npy')\n",
    "x_test = np.load('data/x_test_undersampled.npy')\n",
    "y_test = np.load('data/y_test_undersampled.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5010, 224, 224, 3)\n",
      "(300, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5010,)\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train /= 255????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import time\n",
    "import csv\n",
    "from PIL import Image\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from keras import initializers\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential,load_model,Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import *\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras import callbacks\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as sklm\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "from utils import lossprettifier\n",
    "from Classifier.VGG_bez_dropout import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducibility\n",
    "np.random.seed(3768)\n",
    "\n",
    "# use this environment flag to change which GPU to use \n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"  # specify which GPU(s) to be used\n",
    "\n",
    "#Get TensorFlow session\n",
    "def get_session(): \n",
    "  config = tf.ConfigProto() \n",
    "  config.gpu_options.allow_growth = True \n",
    "  return tf.Session(config=config) \n",
    "  \n",
    "# One hot encoding of labels \n",
    "def dense_to_one_hot(labels_dense,num_clases=4):\n",
    "  return np.eye(num_clases)[labels_dense]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing training and test sets\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = dense_to_one_hot(y_train,num_clases=3)\n",
    "y_valid= dense_to_one_hot(y_valid,num_clases=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:349: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, which overrides setting of `featurewise_center`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    }
   ],
   "source": [
    "#Image data generation for the training \n",
    "datagen = ImageDataGenerator(\n",
    "               featurewise_center = False, \n",
    "               samplewise_center = False,  # set each sample mean to 0\n",
    "               featurewise_std_normalization = True,  \n",
    "               samplewise_std_normalization = False)  \n",
    "\n",
    "datagen.fit(x_train) \n",
    "for i in range(len(x_test)):\n",
    "      x_test[i] = datagen.standardize(x_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hp\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hp\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - 3s 108ms/step - loss: 1.0793 - accuracy: 0.4033 - val_loss: 1.0552 - val_accuracy: 0.4391\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 2s 53ms/step - loss: 1.0103 - accuracy: 0.5132 - val_loss: 0.9352 - val_accuracy: 0.5569\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.8786 - accuracy: 0.6182 - val_loss: 0.9524 - val_accuracy: 0.5469\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.7807 - accuracy: 0.6328 - val_loss: 0.8960 - val_accuracy: 0.6587\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.8450 - accuracy: 0.6426 - val_loss: 1.0615 - val_accuracy: 0.6747\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.8058 - accuracy: 0.6631 - val_loss: 0.6085 - val_accuracy: 0.6607\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.8038 - accuracy: 0.6415 - val_loss: 0.6402 - val_accuracy: 0.7126\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.7133 - accuracy: 0.7129 - val_loss: 0.6485 - val_accuracy: 0.7565\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 1s 47ms/step - loss: 0.6287 - accuracy: 0.7520 - val_loss: 0.5864 - val_accuracy: 0.6986\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.6242 - accuracy: 0.7568 - val_loss: 0.4546 - val_accuracy: 0.7585\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.6359 - accuracy: 0.7305 - val_loss: 0.6935 - val_accuracy: 0.7505\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.6454 - accuracy: 0.7334 - val_loss: 0.7219 - val_accuracy: 0.7565\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.6236 - accuracy: 0.7424 - val_loss: 0.8641 - val_accuracy: 0.7445\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.6682 - accuracy: 0.7346 - val_loss: 0.5564 - val_accuracy: 0.7645\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.6582 - accuracy: 0.7402 - val_loss: 0.6990 - val_accuracy: 0.7485\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.6438 - accuracy: 0.7412 - val_loss: 0.8564 - val_accuracy: 0.7006\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.6207 - accuracy: 0.7373 - val_loss: 0.7409 - val_accuracy: 0.7784\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.6697 - accuracy: 0.7266 - val_loss: 0.5870 - val_accuracy: 0.7725\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.5536 - accuracy: 0.7816 - val_loss: 0.5757 - val_accuracy: 0.7365\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.6449 - accuracy: 0.7412 - val_loss: 0.6577 - val_accuracy: 0.7405\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.5738 - accuracy: 0.7598 - val_loss: 0.5229 - val_accuracy: 0.7345\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.6244 - accuracy: 0.7549 - val_loss: 0.8792 - val_accuracy: 0.7585\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.5506 - accuracy: 0.7920 - val_loss: 0.2873 - val_accuracy: 0.7485\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.6194 - accuracy: 0.7395 - val_loss: 0.3928 - val_accuracy: 0.7425\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.6234 - accuracy: 0.7510 - val_loss: 0.4294 - val_accuracy: 0.7944\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.6030 - accuracy: 0.7559 - val_loss: 0.4200 - val_accuracy: 0.7884\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 2s 47ms/step - loss: 0.5800 - accuracy: 0.7786 - val_loss: 1.2154 - val_accuracy: 0.7485\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.5556 - accuracy: 0.7803 - val_loss: 1.0538 - val_accuracy: 0.6846\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.6235 - accuracy: 0.7607 - val_loss: 0.4389 - val_accuracy: 0.7625\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.5871 - accuracy: 0.7705 - val_loss: 0.5026 - val_accuracy: 0.7465\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 0.5485 - accuracy: 0.7715 - val_loss: 0.5944 - val_accuracy: 0.7844\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.5451 - accuracy: 0.7855 - val_loss: 0.3178 - val_accuracy: 0.7804\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.7526 - accuracy: 0.6904 - val_loss: 1.0014 - val_accuracy: 0.6307\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.7650 - accuracy: 0.6855 - val_loss: 1.0388 - val_accuracy: 0.6647\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.7705 - accuracy: 0.6758 - val_loss: 0.6218 - val_accuracy: 0.7106\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 0.7796 - accuracy: 0.6699 - val_loss: 0.6532 - val_accuracy: 0.6667\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.8291 - accuracy: 0.6318 - val_loss: 0.8932 - val_accuracy: 0.6786\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.7205 - accuracy: 0.7012 - val_loss: 0.7305 - val_accuracy: 0.6747\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.7311 - accuracy: 0.6895 - val_loss: 0.4724 - val_accuracy: 0.7166\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 0.6956 - accuracy: 0.7012 - val_loss: 0.4753 - val_accuracy: 0.7246\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.6627 - accuracy: 0.7275 - val_loss: 0.8607 - val_accuracy: 0.7106\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.6106 - accuracy: 0.7473 - val_loss: 0.4754 - val_accuracy: 0.7804\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.6374 - accuracy: 0.7568 - val_loss: 0.6506 - val_accuracy: 0.7465\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.6176 - accuracy: 0.7598 - val_loss: 0.6365 - val_accuracy: 0.7565\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.5725 - accuracy: 0.7656 - val_loss: 0.7897 - val_accuracy: 0.7884\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.5677 - accuracy: 0.7637 - val_loss: 0.5832 - val_accuracy: 0.7645\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.6177 - accuracy: 0.7646 - val_loss: 0.5772 - val_accuracy: 0.7645\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.6366 - accuracy: 0.7383 - val_loss: 0.6505 - val_accuracy: 0.7685\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 2s 47ms/step - loss: 0.5335 - accuracy: 0.7855 - val_loss: 0.6991 - val_accuracy: 0.7745\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.6572 - accuracy: 0.7197 - val_loss: 0.6368 - val_accuracy: 0.7365\n"
     ]
    }
   ],
   "source": [
    "#Defining hyperparameters\n",
    "batch_Size = 32\n",
    "steps_Per_Epoch = 32\n",
    "numEpochs = 50\n",
    "\n",
    "#Instantating VGG19 model\n",
    "model = VGG19((224,224,3),classes=3) #VGG19_dense for revised VGG19, VGG19 for VGG19. Please pay attention to VGG16(), chnage the input shape and class number in VGG.py.\n",
    "\n",
    "#Creating an optimizers\n",
    "adaDelta = keras.optimizers.Adadelta(lr=1.0, rho=0.95)\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.95, nesterov=True)\n",
    "model.compile(optimizer = sgd , loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "#Creating early stopping \n",
    "earlystop = EarlyStopping(monitor = 'val_accuracy', min_delta = 0, patience = 50, verbose = 1, mode = 'auto', restore_best_weights = True)       \n",
    "\n",
    "train_generator = datagen.flow(x_train, y_train, batch_size = batch_Size)\n",
    "validation_generator = datagen.flow(x_valid, y_valid, batch_size = batch_Size)\n",
    "\n",
    "# Model training\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = steps_Per_Epoch,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = 16,\n",
    "    epochs = numEpochs,\n",
    "    shuffle = True, \n",
    "    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = \"VGG19_COVID19_bez_dropout.h5\"\n",
    "resultPath = 'VGG19_COVID19_bez_dropout.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     0 | LossA: 1.08(+0.00%) \u001b[0m\t| LossAB: 1.06(+0.00%) \u001b[0m\t\n",
      "Epoch     1 | LossA: \u001b[32m1.01(-6.39%) ▼\u001b[0m\t| LossAB: \u001b[32m0.94(-11.38%) ▼\u001b[0m\t\n",
      "Epoch     2 | LossA: \u001b[32m0.88(-13.04%) ▼\u001b[0m\t| LossAB: \u001b[91m0.95(+1.84%) ▲\u001b[0m\t\n",
      "Epoch     3 | LossA: \u001b[32m0.78(-11.13%) ▼\u001b[0m\t| LossAB: \u001b[32m0.90(-5.92%) ▼\u001b[0m\t\n",
      "Epoch     4 | LossA: \u001b[91m0.84(+8.22%) ▲\u001b[0m\t| LossAB: \u001b[91m1.06(+18.47%) ▲\u001b[0m\t\n",
      "Epoch     5 | LossA: \u001b[32m0.81(-4.63%) ▼\u001b[0m\t| LossAB: \u001b[32m0.61(-42.68%) ▼\u001b[0m\t\n",
      "Epoch     6 | LossA: \u001b[32m0.80(-0.36%) ▼\u001b[0m\t| LossAB: \u001b[91m0.64(+5.23%) ▲\u001b[0m\t\n",
      "Epoch     7 | LossA: \u001b[32m0.71(-11.16%) ▼\u001b[0m\t| LossAB: \u001b[91m0.65(+1.29%) ▲\u001b[0m\t\n",
      "Epoch     8 | LossA: \u001b[32m0.63(-11.86%) ▼\u001b[0m\t| LossAB: \u001b[32m0.59(-9.58%) ▼\u001b[0m\t\n",
      "Epoch     9 | LossA: \u001b[32m0.62(-0.71%) ▼\u001b[0m\t| LossAB: \u001b[32m0.45(-22.48%) ▼\u001b[0m\t\n",
      "Epoch    10 | LossA: \u001b[91m0.64(+1.87%) ▲\u001b[0m\t| LossAB: \u001b[91m0.69(+52.55%) ▲\u001b[0m\t\n",
      "Epoch    11 | LossA: \u001b[91m0.65(+1.50%) ▲\u001b[0m\t| LossAB: \u001b[91m0.72(+4.11%) ▲\u001b[0m\t\n",
      "Epoch    12 | LossA: \u001b[32m0.62(-3.47%) ▼\u001b[0m\t| LossAB: \u001b[91m0.86(+19.69%) ▲\u001b[0m\t\n",
      "Epoch    13 | LossA: \u001b[91m0.67(+7.24%) ▲\u001b[0m\t| LossAB: \u001b[32m0.56(-35.60%) ▼\u001b[0m\t\n",
      "Epoch    14 | LossA: \u001b[32m0.66(-1.49%) ▼\u001b[0m\t| LossAB: \u001b[91m0.70(+25.62%) ▲\u001b[0m\t\n",
      "Epoch    15 | LossA: \u001b[32m0.64(-2.18%) ▼\u001b[0m\t| LossAB: \u001b[91m0.86(+22.52%) ▲\u001b[0m\t\n",
      "Epoch    16 | LossA: \u001b[32m0.62(-3.59%) ▼\u001b[0m\t| LossAB: \u001b[32m0.74(-13.48%) ▼\u001b[0m\t\n",
      "Epoch    17 | LossA: \u001b[91m0.67(+7.89%) ▲\u001b[0m\t| LossAB: \u001b[32m0.59(-20.78%) ▼\u001b[0m\t\n",
      "Epoch    18 | LossA: \u001b[32m0.55(-17.30%) ▼\u001b[0m\t| LossAB: \u001b[32m0.58(-1.92%) ▼\u001b[0m\t\n",
      "Epoch    19 | LossA: \u001b[91m0.64(+16.44%) ▲\u001b[0m\t| LossAB: \u001b[91m0.66(+14.24%) ▲\u001b[0m\t\n",
      "Epoch    20 | LossA: \u001b[32m0.57(-11.01%) ▼\u001b[0m\t| LossAB: \u001b[32m0.52(-20.50%) ▼\u001b[0m\t\n",
      "Epoch    21 | LossA: \u001b[91m0.62(+8.82%) ▲\u001b[0m\t| LossAB: \u001b[91m0.88(+68.15%) ▲\u001b[0m\t\n",
      "Epoch    22 | LossA: \u001b[32m0.55(-11.83%) ▼\u001b[0m\t| LossAB: \u001b[32m0.29(-67.32%) ▼\u001b[0m\t\n",
      "Epoch    23 | LossA: \u001b[91m0.62(+12.52%) ▲\u001b[0m\t| LossAB: \u001b[91m0.39(+36.71%) ▲\u001b[0m\t\n",
      "Epoch    24 | LossA: \u001b[91m0.62(+0.64%) ▲\u001b[0m\t| LossAB: \u001b[91m0.43(+9.30%) ▲\u001b[0m\t\n",
      "Epoch    25 | LossA: \u001b[32m0.60(-3.27%) ▼\u001b[0m\t| LossAB: \u001b[32m0.42(-2.18%) ▼\u001b[0m\t\n",
      "Epoch    26 | LossA: \u001b[32m0.58(-3.81%) ▼\u001b[0m\t| LossAB: \u001b[91m1.22(+189.37%) ▲\u001b[0m\t\n",
      "Epoch    27 | LossA: \u001b[32m0.56(-4.21%) ▼\u001b[0m\t| LossAB: \u001b[32m1.05(-13.30%) ▼\u001b[0m\t\n",
      "Epoch    28 | LossA: \u001b[91m0.62(+12.23%) ▲\u001b[0m\t| LossAB: \u001b[32m0.44(-58.35%) ▼\u001b[0m\t\n",
      "Epoch    29 | LossA: \u001b[32m0.59(-5.84%) ▼\u001b[0m\t| LossAB: \u001b[91m0.50(+14.52%) ▲\u001b[0m\t\n",
      "Epoch    30 | LossA: \u001b[32m0.55(-6.58%) ▼\u001b[0m\t| LossAB: \u001b[91m0.59(+18.28%) ▲\u001b[0m\t\n",
      "Epoch    31 | LossA: \u001b[32m0.55(-0.60%) ▼\u001b[0m\t| LossAB: \u001b[32m0.32(-46.53%) ▼\u001b[0m\t\n",
      "Epoch    32 | LossA: \u001b[91m0.75(+38.06%) ▲\u001b[0m\t| LossAB: \u001b[91m1.00(+215.08%) ▲\u001b[0m\t\n",
      "Epoch    33 | LossA: \u001b[91m0.77(+1.64%) ▲\u001b[0m\t| LossAB: \u001b[91m1.04(+3.73%) ▲\u001b[0m\t\n",
      "Epoch    34 | LossA: \u001b[91m0.77(+0.72%) ▲\u001b[0m\t| LossAB: \u001b[32m0.62(-40.14%) ▼\u001b[0m\t\n",
      "Epoch    35 | LossA: \u001b[91m0.78(+1.16%) ▲\u001b[0m\t| LossAB: \u001b[91m0.65(+5.04%) ▲\u001b[0m\t\n",
      "Epoch    36 | LossA: \u001b[91m0.83(+6.38%) ▲\u001b[0m\t| LossAB: \u001b[91m0.89(+36.75%) ▲\u001b[0m\t\n",
      "Epoch    37 | LossA: \u001b[32m0.72(-13.10%) ▼\u001b[0m\t| LossAB: \u001b[32m0.73(-18.22%) ▼\u001b[0m\t\n",
      "Epoch    38 | LossA: \u001b[91m0.73(+1.46%) ▲\u001b[0m\t| LossAB: \u001b[32m0.47(-35.33%) ▼\u001b[0m\t\n",
      "Epoch    39 | LossA: \u001b[32m0.70(-4.85%) ▼\u001b[0m\t| LossAB: \u001b[91m0.48(+0.61%) ▲\u001b[0m\t\n",
      "Epoch    40 | LossA: \u001b[32m0.66(-4.73%) ▼\u001b[0m\t| LossAB: \u001b[91m0.86(+81.08%) ▲\u001b[0m\t\n",
      "Epoch    41 | LossA: \u001b[32m0.61(-7.88%) ▼\u001b[0m\t| LossAB: \u001b[32m0.48(-44.76%) ▼\u001b[0m\t\n",
      "Epoch    42 | LossA: \u001b[91m0.64(+4.40%) ▲\u001b[0m\t| LossAB: \u001b[91m0.65(+36.85%) ▲\u001b[0m\t\n",
      "Epoch    43 | LossA: \u001b[32m0.62(-3.10%) ▼\u001b[0m\t| LossAB: \u001b[32m0.64(-2.16%) ▼\u001b[0m\t\n",
      "Epoch    44 | LossA: \u001b[32m0.57(-7.30%) ▼\u001b[0m\t| LossAB: \u001b[91m0.79(+24.06%) ▲\u001b[0m\t\n",
      "Epoch    45 | LossA: \u001b[32m0.57(-0.85%) ▼\u001b[0m\t| LossAB: \u001b[32m0.58(-26.15%) ▼\u001b[0m\t\n",
      "Epoch    46 | LossA: \u001b[91m0.62(+8.81%) ▲\u001b[0m\t| LossAB: \u001b[32m0.58(-1.03%) ▼\u001b[0m\t\n",
      "Epoch    47 | LossA: \u001b[91m0.64(+3.07%) ▲\u001b[0m\t| LossAB: \u001b[91m0.65(+12.70%) ▲\u001b[0m\t\n",
      "Epoch    48 | LossA: \u001b[32m0.53(-16.35%) ▼\u001b[0m\t| LossAB: \u001b[91m0.70(+7.48%) ▲\u001b[0m\t\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Accuracy: 0.7133333086967468\n"
     ]
    }
   ],
   "source": [
    "y_test_oh = dense_to_one_hot(y_test, num_clases=3)\n",
    "\n",
    "# visualizing losses and accuracy\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "#Observing the losses but can be commented out as it's not mandatory \n",
    "reporter = lossprettifier.LossPrettifier(show_percentage=True)\n",
    "\n",
    "for i in range(numEpochs-1):\n",
    "    reporter(epoch=i, LossA = train_loss[i], LossAB = val_loss[i])\n",
    "\n",
    "# Model evaluation \n",
    "score, acc = model.evaluate(x_test, y_test_oh, batch_size=batch_Size)\n",
    "print(\"Accuracy:\", acc)\n",
    "\n",
    "#if acc>0.675:\n",
    "model.save_weights(modelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.60      0.72       100\n",
      "           1       0.62      0.78      0.69       100\n",
      "           2       0.70      0.76      0.73       100\n",
      "\n",
      "    accuracy                           0.71       300\n",
      "   macro avg       0.74      0.71      0.71       300\n",
      "weighted avg       0.74      0.71      0.71       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_pred = y_pred.reshape(len(y_test), 3)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Writing results on file\n",
    "f = open(resultPath,'a') #create classification report\n",
    "f.write(classification_report(y_test, y_pred))\n",
    "f.write(str(sklm.cohen_kappa_score(y_test, y_pred))+\",\"+str(acc)+\",\"+str(score)+\"\\n\")\n",
    "\n",
    "#Print class-wise classification metrics\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.array(['normal', 'COVID19', 'pneumonia']))\n",
    "disp.plot(cmap='Blues') \n",
    "disp.ax_.get_images()[0].set_clim(0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wbvenv36",
   "language": "python",
   "name": "wbvenv36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
