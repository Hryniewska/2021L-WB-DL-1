{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sys import path\n",
    "path.insert(0,'..')\n",
    "from utils import lossprettifier\n",
    "from Classifier.VGG import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train = np.load('data1/x_train.npy')\n",
    "#y_train = np.load('data1/y_train.npy')\n",
    "#x_test = np.load('data1/x_test.npy')\n",
    "#y_test = np.load('data1/y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('preprocessed/x_train_prep.npy')\n",
    "y_train = np.load('preprocessed/y_train_prep.npy')\n",
    "x_test = np.load('preprocessed/x_test_prep.npy')\n",
    "y_test = np.load('preprocessed/y_test_prep.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train = np.load('data1/x_train_prep.npy')\n",
    "#y_train = np.load('data1/y_train_prep.npy')\n",
    "#x_test = np.load('data1/x_test_prep.npy')\n",
    "#y_test = np.load('data1/y_test_prep.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x_train.shape)\n",
    "#print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(y_train.shape)\n",
    "#print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train /= 255????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import time\n",
    "import csv\n",
    "from PIL import Image\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from keras import initializers\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential,load_model,Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import *\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras import callbacks\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as sklm\n",
    "#import lossprettifier\n",
    "#from VGG import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducibility\n",
    "np.random.seed(3768)\n",
    "\n",
    "# use this environment flag to change which GPU to use \n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"  # specify which GPU(s) to be used\n",
    "\n",
    "#Get TensorFlow session\n",
    "def get_session(): \n",
    "  config = tf.ConfigProto() \n",
    "  config.gpu_options.allow_growth = True \n",
    "  return tf.Session(config=config) \n",
    "  \n",
    "# One hot encoding of labels \n",
    "def dense_to_one_hot(labels_dense,num_clases=3):\n",
    "  return np.eye(num_clases)[labels_dense]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing training and test sets\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = dense_to_one_hot(y_train,num_clases=3)\n",
    "y_valid= dense_to_one_hot(y_valid,num_clases=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aleksander Podsiad\\.conda\\envs\\WB_env_tf_1_15_2\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:349: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, which overrides setting of `featurewise_center`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    }
   ],
   "source": [
    "#Image data generation for the training \n",
    "datagen = ImageDataGenerator(\n",
    "               featurewise_center = False, \n",
    "               samplewise_center = False,  # set each sample mean to 0\n",
    "               featurewise_std_normalization = True,  \n",
    "               samplewise_std_normalization = False)  \n",
    "\n",
    "datagen.fit(x_train) \n",
    "for i in range(len(x_test)):\n",
    "      x_test[i] = datagen.standardize(x_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLearningRateScheduler(keras.callbacks.Callback):\n",
    "    \"\"\"Learning rate scheduler which sets the learning rate according to schedule.\n",
    "\n",
    "  Arguments:\n",
    "      schedule: a function that takes an epoch index\n",
    "          (integer, indexed from 0) and current learning rate\n",
    "          as inputs and returns a new learning rate as output (float).\n",
    "  \"\"\"\n",
    "\n",
    "    def __init__(self, schedule):\n",
    "        super(CustomLearningRateScheduler, self).__init__()\n",
    "        self.schedule = schedule\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        if not hasattr(self.model.optimizer, \"lr\"):\n",
    "            raise ValueError('Optimizer must have a \"lr\" attribute.')\n",
    "        # Get the current learning rate from model's optimizer.\n",
    "        lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n",
    "        # Call schedule function to get the scheduled learning rate.\n",
    "        scheduled_lr = self.schedule(epoch, lr)\n",
    "        # Set the value back to the optimizer before this epoch starts\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr, scheduled_lr)\n",
    "        print(\"\\nEpoch %05d: Learning rate is %6.4f.\" % (epoch, scheduled_lr))\n",
    "\n",
    "\n",
    "LR_SCHEDULE = [\n",
    "    # (epoch to start, learning rate) tuples\n",
    "    (10, 0.005),\n",
    "    (20, 0.001),\n",
    "    (40, 0.0005),\n",
    "    (50, 0.0001),\n",
    "]\n",
    "\n",
    "\n",
    "def lr_schedule(epoch, lr):\n",
    "    \"\"\"Helper function to retrieve the scheduled learning rate based on epoch.\"\"\"\n",
    "    if epoch < LR_SCHEDULE[0][0] or epoch > LR_SCHEDULE[-1][0]:\n",
    "        return lr\n",
    "    for i in range(len(LR_SCHEDULE)):\n",
    "        if epoch == LR_SCHEDULE[i][0]:\n",
    "            return LR_SCHEDULE[i][1]\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard setup\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir, histogram_freq=1, write_graph=True)\n",
    "earlystop = EarlyStopping(monitor = 'val_accuracy', min_delta = 0, patience = 50, \n",
    "                          verbose = 1, mode = 'auto', restore_best_weights = True) \n",
    "lrs = CustomLearningRateScheduler(lr_schedule)\n",
    "\n",
    "\n",
    "my_callbacks = [tensorboard_callback, earlystop, lrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\n",
      "Epoch 00000: Learning rate is 0.0100.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aleksander Podsiad\\.conda\\envs\\WB_env_tf_1_15_2\\lib\\site-packages\\keras\\callbacks\\callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.932507). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 19s - loss: 1.0999 - accuracy: 0.3408 - val_loss: 1.0536 - val_accuracy: 0.3516\n",
      "Epoch 2/60\n",
      "\n",
      "Epoch 00001: Learning rate is 0.0100.\n",
      " - 13s - loss: 1.0763 - accuracy: 0.4213 - val_loss: 1.0269 - val_accuracy: 0.4703\n",
      "Epoch 3/60\n",
      "\n",
      "Epoch 00002: Learning rate is 0.0100.\n",
      " - 15s - loss: 0.9791 - accuracy: 0.5371 - val_loss: 0.9162 - val_accuracy: 0.5447\n",
      "Epoch 4/60\n",
      "\n",
      "Epoch 00003: Learning rate is 0.0100.\n",
      " - 15s - loss: 0.8770 - accuracy: 0.6016 - val_loss: 0.7687 - val_accuracy: 0.6314\n",
      "Epoch 5/60\n",
      "\n",
      "Epoch 00004: Learning rate is 0.0100.\n",
      " - 15s - loss: 0.8456 - accuracy: 0.6221 - val_loss: 0.9383 - val_accuracy: 0.6801\n",
      "Epoch 6/60\n",
      "\n",
      "Epoch 00005: Learning rate is 0.0100.\n",
      " - 15s - loss: 0.8447 - accuracy: 0.6484 - val_loss: 0.8501 - val_accuracy: 0.7073\n",
      "Epoch 7/60\n",
      "\n",
      "Epoch 00006: Learning rate is 0.0100.\n",
      " - 14s - loss: 0.7648 - accuracy: 0.6683 - val_loss: 0.8191 - val_accuracy: 0.6907\n",
      "Epoch 8/60\n",
      "\n",
      "Epoch 00007: Learning rate is 0.0100.\n",
      " - 15s - loss: 0.7627 - accuracy: 0.6719 - val_loss: 0.5986 - val_accuracy: 0.6646\n",
      "Epoch 9/60\n",
      "\n",
      "Epoch 00008: Learning rate is 0.0100.\n",
      " - 14s - loss: 0.7480 - accuracy: 0.6793 - val_loss: 0.8879 - val_accuracy: 0.7267\n",
      "Epoch 10/60\n",
      "\n",
      "Epoch 00009: Learning rate is 0.0100.\n",
      " - 15s - loss: 0.7473 - accuracy: 0.6797 - val_loss: 0.6451 - val_accuracy: 0.7373\n",
      "Epoch 11/60\n",
      "\n",
      "Epoch 00010: Learning rate is 0.0050.\n",
      " - 15s - loss: 0.6964 - accuracy: 0.7139 - val_loss: 0.6252 - val_accuracy: 0.6728\n",
      "Epoch 12/60\n",
      "\n",
      "Epoch 00011: Learning rate is 0.0050.\n",
      " - 15s - loss: 0.6961 - accuracy: 0.7051 - val_loss: 0.7720 - val_accuracy: 0.7225\n",
      "Epoch 13/60\n",
      "\n",
      "Epoch 00012: Learning rate is 0.0050.\n",
      " - 15s - loss: 0.6751 - accuracy: 0.7171 - val_loss: 0.6304 - val_accuracy: 0.7581\n",
      "Epoch 14/60\n",
      "\n",
      "Epoch 00013: Learning rate is 0.0050.\n",
      " - 14s - loss: 0.6566 - accuracy: 0.7171 - val_loss: 0.6208 - val_accuracy: 0.7458\n",
      "Epoch 15/60\n",
      "\n",
      "Epoch 00014: Learning rate is 0.0050.\n",
      " - 15s - loss: 0.6324 - accuracy: 0.7314 - val_loss: 0.4737 - val_accuracy: 0.7288\n",
      "Epoch 16/60\n",
      "\n",
      "Epoch 00015: Learning rate is 0.0050.\n",
      " - 15s - loss: 0.6752 - accuracy: 0.7266 - val_loss: 0.7483 - val_accuracy: 0.7297\n",
      "Epoch 17/60\n",
      "\n",
      "Epoch 00016: Learning rate is 0.0050.\n",
      " - 15s - loss: 0.6325 - accuracy: 0.7460 - val_loss: 0.7679 - val_accuracy: 0.7987\n",
      "Epoch 18/60\n",
      "\n",
      "Epoch 00017: Learning rate is 0.0050.\n",
      " - 15s - loss: 0.6026 - accuracy: 0.7588 - val_loss: 0.4586 - val_accuracy: 0.7642\n",
      "Epoch 19/60\n",
      "\n",
      "Epoch 00018: Learning rate is 0.0050.\n",
      " - 15s - loss: 0.5825 - accuracy: 0.7529 - val_loss: 0.4420 - val_accuracy: 0.7903\n",
      "Epoch 20/60\n",
      "\n",
      "Epoch 00019: Learning rate is 0.0050.\n",
      " - 15s - loss: 0.5646 - accuracy: 0.7842 - val_loss: 0.5294 - val_accuracy: 0.7733\n",
      "Epoch 21/60\n",
      "\n",
      "Epoch 00020: Learning rate is 0.0010.\n",
      " - 15s - loss: 0.6253 - accuracy: 0.7450 - val_loss: 0.5786 - val_accuracy: 0.8049\n",
      "Epoch 22/60\n",
      "\n",
      "Epoch 00021: Learning rate is 0.0010.\n",
      " - 15s - loss: 0.5515 - accuracy: 0.7832 - val_loss: 0.6820 - val_accuracy: 0.7987\n",
      "Epoch 23/60\n",
      "\n",
      "Epoch 00022: Learning rate is 0.0010.\n",
      " - 15s - loss: 0.5102 - accuracy: 0.7910 - val_loss: 0.6418 - val_accuracy: 0.8049\n",
      "Epoch 24/60\n",
      "\n",
      "Epoch 00023: Learning rate is 0.0010.\n",
      " - 14s - loss: 0.5414 - accuracy: 0.7839 - val_loss: 0.5506 - val_accuracy: 0.8114\n",
      "Epoch 25/60\n",
      "\n",
      "Epoch 00024: Learning rate is 0.0010.\n",
      " - 15s - loss: 0.4933 - accuracy: 0.8207 - val_loss: 0.6280 - val_accuracy: 0.8008\n",
      "Epoch 26/60\n",
      "\n",
      "Epoch 00025: Learning rate is 0.0010.\n",
      " - 15s - loss: 0.5050 - accuracy: 0.8018 - val_loss: 0.7133 - val_accuracy: 0.8028\n",
      "Epoch 27/60\n",
      "\n",
      "Epoch 00026: Learning rate is 0.0010.\n",
      " - 16s - loss: 0.5140 - accuracy: 0.8008 - val_loss: 0.7271 - val_accuracy: 0.8199\n",
      "Epoch 28/60\n",
      "\n",
      "Epoch 00027: Learning rate is 0.0010.\n",
      " - 15s - loss: 0.4987 - accuracy: 0.8047 - val_loss: 0.7933 - val_accuracy: 0.8211\n",
      "Epoch 29/60\n",
      "\n",
      "Epoch 00028: Learning rate is 0.0010.\n",
      " - 15s - loss: 0.4630 - accuracy: 0.8227 - val_loss: 0.3326 - val_accuracy: 0.7839\n",
      "Epoch 30/60\n",
      "\n",
      "Epoch 00029: Learning rate is 0.0010.\n",
      " - 15s - loss: 0.4772 - accuracy: 0.8066 - val_loss: 1.0062 - val_accuracy: 0.8220\n",
      "Epoch 31/60\n",
      "\n",
      "Epoch 00030: Learning rate is 0.0010.\n",
      " - 15s - loss: 0.4768 - accuracy: 0.8145 - val_loss: 0.6974 - val_accuracy: 0.7988\n",
      "Epoch 32/60\n",
      "\n",
      "Epoch 00031: Learning rate is 0.0010.\n",
      " - 15s - loss: 0.4628 - accuracy: 0.8217 - val_loss: 0.4700 - val_accuracy: 0.8114\n",
      "Epoch 33/60\n",
      "\n",
      "Epoch 00032: Learning rate is 0.0010.\n",
      " - 15s - loss: 0.4579 - accuracy: 0.8145 - val_loss: 0.5169 - val_accuracy: 0.8293\n",
      "Epoch 34/60\n",
      "\n",
      "Epoch 00033: Learning rate is 0.0010.\n",
      " - 15s - loss: 0.4338 - accuracy: 0.8252 - val_loss: 0.5923 - val_accuracy: 0.8030\n",
      "Epoch 35/60\n",
      "\n",
      "Epoch 00034: Learning rate is 0.0010.\n",
      " - 15s - loss: 0.4319 - accuracy: 0.8237 - val_loss: 1.1703 - val_accuracy: 0.8157\n",
      "Epoch 36/60\n",
      "\n",
      "Epoch 00035: Learning rate is 0.0010.\n",
      " - 15s - loss: 0.4275 - accuracy: 0.8330 - val_loss: 0.8541 - val_accuracy: 0.7927\n",
      "Epoch 37/60\n",
      "\n",
      "Epoch 00036: Learning rate is 0.0010.\n",
      " - 15s - loss: 0.4383 - accuracy: 0.8367 - val_loss: 0.5296 - val_accuracy: 0.8136\n",
      "Epoch 38/60\n",
      "\n",
      "Epoch 00037: Learning rate is 0.0010.\n",
      " - 15s - loss: 0.4106 - accuracy: 0.8406 - val_loss: 0.4581 - val_accuracy: 0.8110\n",
      "Epoch 39/60\n",
      "\n",
      "Epoch 00038: Learning rate is 0.0010.\n",
      " - 15s - loss: 0.4173 - accuracy: 0.8438 - val_loss: 0.5502 - val_accuracy: 0.8008\n",
      "Epoch 40/60\n",
      "\n",
      "Epoch 00039: Learning rate is 0.0010.\n",
      " - 15s - loss: 0.4268 - accuracy: 0.8320 - val_loss: 0.1901 - val_accuracy: 0.8008\n",
      "Epoch 41/60\n",
      "\n",
      "Epoch 00040: Learning rate is 0.0005.\n",
      " - 15s - loss: 0.4128 - accuracy: 0.8486 - val_loss: 0.2604 - val_accuracy: 0.8272\n",
      "Epoch 42/60\n",
      "\n",
      "Epoch 00041: Learning rate is 0.0005.\n",
      " - 15s - loss: 0.3928 - accuracy: 0.8555 - val_loss: 0.6208 - val_accuracy: 0.8093\n",
      "Epoch 43/60\n",
      "\n",
      "Epoch 00042: Learning rate is 0.0005.\n",
      " - 15s - loss: 0.3853 - accuracy: 0.8506 - val_loss: 0.3187 - val_accuracy: 0.8008\n",
      "Epoch 44/60\n",
      "\n",
      "Epoch 00043: Learning rate is 0.0005.\n",
      " - 15s - loss: 0.3668 - accuracy: 0.8545 - val_loss: 0.4236 - val_accuracy: 0.8284\n",
      "Epoch 45/60\n",
      "\n",
      "Epoch 00044: Learning rate is 0.0005.\n",
      " - 15s - loss: 0.3664 - accuracy: 0.8655 - val_loss: 0.2686 - val_accuracy: 0.8051\n",
      "Epoch 46/60\n",
      "\n",
      "Epoch 00045: Learning rate is 0.0005.\n",
      " - 15s - loss: 0.3697 - accuracy: 0.8525 - val_loss: 0.3712 - val_accuracy: 0.8252\n",
      "Epoch 47/60\n",
      "\n",
      "Epoch 00046: Learning rate is 0.0005.\n",
      " - 15s - loss: 0.3487 - accuracy: 0.8799 - val_loss: 0.4800 - val_accuracy: 0.7945\n",
      "Epoch 48/60\n",
      "\n",
      "Epoch 00047: Learning rate is 0.0005.\n",
      " - 15s - loss: 0.4034 - accuracy: 0.8357 - val_loss: 0.3922 - val_accuracy: 0.8089\n",
      "Epoch 49/60\n",
      "\n",
      "Epoch 00048: Learning rate is 0.0005.\n",
      " - 15s - loss: 0.3410 - accuracy: 0.8682 - val_loss: 0.5701 - val_accuracy: 0.8220\n",
      "Epoch 50/60\n",
      "\n",
      "Epoch 00049: Learning rate is 0.0005.\n",
      " - 15s - loss: 0.3768 - accuracy: 0.8635 - val_loss: 0.5130 - val_accuracy: 0.8220\n",
      "Epoch 51/60\n",
      "\n",
      "Epoch 00050: Learning rate is 0.0001.\n",
      " - 15s - loss: 0.3146 - accuracy: 0.8916 - val_loss: 0.5364 - val_accuracy: 0.8171\n",
      "Epoch 52/60\n",
      "\n",
      "Epoch 00051: Learning rate is 0.0001.\n",
      " - 15s - loss: 0.3736 - accuracy: 0.8416 - val_loss: 0.6158 - val_accuracy: 0.8326\n",
      "Epoch 53/60\n",
      "\n",
      "Epoch 00052: Learning rate is 0.0001.\n",
      " - 15s - loss: 0.3414 - accuracy: 0.8750 - val_loss: 0.8664 - val_accuracy: 0.8110\n",
      "Epoch 54/60\n",
      "\n",
      "Epoch 00053: Learning rate is 0.0001.\n",
      " - 15s - loss: 0.3100 - accuracy: 0.8755 - val_loss: 0.2379 - val_accuracy: 0.8114\n",
      "Epoch 55/60\n",
      "\n",
      "Epoch 00054: Learning rate is 0.0001.\n",
      " - 15s - loss: 0.3529 - accuracy: 0.8613 - val_loss: 0.6166 - val_accuracy: 0.8199\n",
      "Epoch 56/60\n",
      "\n",
      "Epoch 00055: Learning rate is 0.0001.\n",
      " - 15s - loss: 0.2992 - accuracy: 0.8809 - val_loss: 0.7881 - val_accuracy: 0.8252\n",
      "Epoch 57/60\n",
      "\n",
      "Epoch 00056: Learning rate is 0.0001.\n",
      " - 15s - loss: 0.3601 - accuracy: 0.8765 - val_loss: 0.4935 - val_accuracy: 0.8242\n",
      "Epoch 58/60\n",
      "\n",
      "Epoch 00057: Learning rate is 0.0001.\n",
      " - 16s - loss: 0.3072 - accuracy: 0.8916 - val_loss: 0.5894 - val_accuracy: 0.8008\n",
      "Epoch 59/60\n",
      "\n",
      "Epoch 00058: Learning rate is 0.0001.\n",
      " - 15s - loss: 0.2816 - accuracy: 0.8955 - val_loss: 0.4251 - val_accuracy: 0.8263\n",
      "Epoch 60/60\n",
      "\n",
      "Epoch 00059: Learning rate is 0.0001.\n",
      " - 15s - loss: 0.3265 - accuracy: 0.8795 - val_loss: 0.1764 - val_accuracy: 0.8178\n"
     ]
    }
   ],
   "source": [
    "#Defining hyperparameters\n",
    "batch_Size = 32\n",
    "steps_Per_Epoch = 32\n",
    "numEpochs = 60\n",
    "\n",
    "#Instantating VGG19 model\n",
    "model = VGG19((224,224,3),3) #VGG19_dense for revised VGG19, VGG19 for VGG19. Please pay attention to VGG16(), chnage the input shape and class number in VGG.py.\n",
    "\n",
    "model.run_eagerly=True\n",
    "\n",
    "#Creating an optimizers\n",
    "adaDelta = keras.optimizers.Adadelta(lr=1.0, rho=0.95)\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.95, nesterov=True)\n",
    "model.compile(optimizer = sgd , loss = 'categorical_crossentropy', metrics = ['accuracy'])      \n",
    "\n",
    "train_generator = datagen.flow(x_train, y_train, batch_size = batch_Size)\n",
    "validation_generator = datagen.flow(x_valid, y_valid, batch_size = batch_Size)\n",
    "\n",
    "# Model training\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch = steps_Per_Epoch,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = 16,\n",
    "    epochs = numEpochs,\n",
    "    shuffle = True, \n",
    "    verbose = 2, \n",
    "    callbacks = my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = \"VGG19_COVID19_tboard.h5\"\n",
    "resultPath = 'VGG19_COVID19_tboard.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_train # clear memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     0 | LossA: 1.10(+0.00%) \u001b[0m\t| LossAB: 1.05(+0.00%) \u001b[0m\t\n",
      "Epoch     1 | LossA: \u001b[32m1.08(-1.99%) ▼\u001b[0m\t| LossAB: \u001b[32m1.03(-2.54%) ▼\u001b[0m\t\n",
      "Epoch     2 | LossA: \u001b[32m0.98(-9.18%) ▼\u001b[0m\t| LossAB: \u001b[32m0.92(-10.78%) ▼\u001b[0m\t\n",
      "Epoch     3 | LossA: \u001b[32m0.88(-10.58%) ▼\u001b[0m\t| LossAB: \u001b[32m0.77(-16.10%) ▼\u001b[0m\t\n",
      "Epoch     4 | LossA: \u001b[32m0.85(-3.42%) ▼\u001b[0m\t| LossAB: \u001b[91m0.94(+22.06%) ▲\u001b[0m\t\n",
      "Epoch     5 | LossA: \u001b[32m0.84(-0.10%) ▼\u001b[0m\t| LossAB: \u001b[32m0.85(-9.40%) ▼\u001b[0m\t\n",
      "Epoch     6 | LossA: \u001b[32m0.77(-8.93%) ▼\u001b[0m\t| LossAB: \u001b[32m0.82(-3.65%) ▼\u001b[0m\t\n",
      "Epoch     7 | LossA: \u001b[32m0.76(-0.86%) ▼\u001b[0m\t| LossAB: \u001b[32m0.60(-26.92%) ▼\u001b[0m\t\n",
      "Epoch     8 | LossA: \u001b[32m0.74(-2.74%) ▼\u001b[0m\t| LossAB: \u001b[91m0.89(+48.32%) ▲\u001b[0m\t\n",
      "Epoch     9 | LossA: \u001b[91m0.75(+0.74%) ▲\u001b[0m\t| LossAB: \u001b[32m0.65(-27.34%) ▼\u001b[0m\t\n",
      "Epoch    10 | LossA: \u001b[32m0.70(-6.81%) ▼\u001b[0m\t| LossAB: \u001b[32m0.63(-3.09%) ▼\u001b[0m\t\n",
      "Epoch    11 | LossA: \u001b[32m0.70(-0.03%) ▼\u001b[0m\t| LossAB: \u001b[91m0.77(+23.48%) ▲\u001b[0m\t\n",
      "Epoch    12 | LossA: \u001b[32m0.68(-2.72%) ▼\u001b[0m\t| LossAB: \u001b[32m0.63(-18.34%) ▼\u001b[0m\t\n",
      "Epoch    13 | LossA: \u001b[32m0.66(-3.13%) ▼\u001b[0m\t| LossAB: \u001b[32m0.62(-1.53%) ▼\u001b[0m\t\n",
      "Epoch    14 | LossA: \u001b[32m0.63(-3.59%) ▼\u001b[0m\t| LossAB: \u001b[32m0.47(-23.68%) ▼\u001b[0m\t\n",
      "Epoch    15 | LossA: \u001b[91m0.68(+6.77%) ▲\u001b[0m\t| LossAB: \u001b[91m0.75(+57.96%) ▲\u001b[0m\t\n",
      "Epoch    16 | LossA: \u001b[32m0.64(-5.78%) ▼\u001b[0m\t| LossAB: \u001b[91m0.77(+2.62%) ▲\u001b[0m\t\n",
      "Epoch    17 | LossA: \u001b[32m0.60(-5.28%) ▼\u001b[0m\t| LossAB: \u001b[32m0.46(-40.28%) ▼\u001b[0m\t\n",
      "Epoch    18 | LossA: \u001b[32m0.58(-3.34%) ▼\u001b[0m\t| LossAB: \u001b[32m0.44(-3.61%) ▼\u001b[0m\t\n",
      "Epoch    19 | LossA: \u001b[32m0.56(-3.08%) ▼\u001b[0m\t| LossAB: \u001b[91m0.53(+19.76%) ▲\u001b[0m\t\n",
      "Epoch    20 | LossA: \u001b[91m0.63(+11.11%) ▲\u001b[0m\t| LossAB: \u001b[91m0.58(+9.29%) ▲\u001b[0m\t\n",
      "Epoch    21 | LossA: \u001b[32m0.55(-12.08%) ▼\u001b[0m\t| LossAB: \u001b[91m0.68(+17.88%) ▲\u001b[0m\t\n",
      "Epoch    22 | LossA: \u001b[32m0.51(-7.49%) ▼\u001b[0m\t| LossAB: \u001b[32m0.64(-5.89%) ▼\u001b[0m\t\n",
      "Epoch    23 | LossA: \u001b[91m0.55(+7.13%) ▲\u001b[0m\t| LossAB: \u001b[32m0.55(-14.22%) ▼\u001b[0m\t\n",
      "Epoch    24 | LossA: \u001b[32m0.49(-10.60%) ▼\u001b[0m\t| LossAB: \u001b[91m0.63(+14.06%) ▲\u001b[0m\t\n",
      "Epoch    25 | LossA: \u001b[91m0.51(+3.36%) ▲\u001b[0m\t| LossAB: \u001b[91m0.71(+13.57%) ▲\u001b[0m\t\n",
      "Epoch    26 | LossA: \u001b[91m0.51(+1.77%) ▲\u001b[0m\t| LossAB: \u001b[91m0.73(+1.94%) ▲\u001b[0m\t\n",
      "Epoch    27 | LossA: \u001b[32m0.50(-2.97%) ▼\u001b[0m\t| LossAB: \u001b[91m0.79(+9.11%) ▲\u001b[0m\t\n",
      "Epoch    28 | LossA: \u001b[32m0.47(-6.23%) ▼\u001b[0m\t| LossAB: \u001b[32m0.33(-58.08%) ▼\u001b[0m\t\n",
      "Epoch    29 | LossA: \u001b[91m0.48(+2.05%) ▲\u001b[0m\t| LossAB: \u001b[91m1.01(+202.56%) ▲\u001b[0m\t\n",
      "Epoch    30 | LossA: \u001b[32m0.48(-0.08%) ▼\u001b[0m\t| LossAB: \u001b[32m0.70(-30.69%) ▼\u001b[0m\t\n",
      "Epoch    31 | LossA: \u001b[32m0.46(-2.74%) ▼\u001b[0m\t| LossAB: \u001b[32m0.47(-32.61%) ▼\u001b[0m\t\n",
      "Epoch    32 | LossA: \u001b[32m0.46(-1.27%) ▼\u001b[0m\t| LossAB: \u001b[91m0.52(+9.98%) ▲\u001b[0m\t\n",
      "Epoch    33 | LossA: \u001b[32m0.43(-5.25%) ▼\u001b[0m\t| LossAB: \u001b[91m0.59(+14.59%) ▲\u001b[0m\t\n",
      "Epoch    34 | LossA: \u001b[32m0.43(-0.88%) ▼\u001b[0m\t| LossAB: \u001b[91m1.17(+97.59%) ▲\u001b[0m\t\n",
      "Epoch    35 | LossA: \u001b[32m0.43(-0.58%) ▼\u001b[0m\t| LossAB: \u001b[32m0.85(-27.02%) ▼\u001b[0m\t\n",
      "Epoch    36 | LossA: \u001b[91m0.44(+2.55%) ▲\u001b[0m\t| LossAB: \u001b[32m0.53(-38.00%) ▼\u001b[0m\t\n",
      "Epoch    37 | LossA: \u001b[32m0.41(-6.86%) ▼\u001b[0m\t| LossAB: \u001b[32m0.46(-13.49%) ▼\u001b[0m\t\n",
      "Epoch    38 | LossA: \u001b[91m0.42(+2.20%) ▲\u001b[0m\t| LossAB: \u001b[91m0.55(+20.10%) ▲\u001b[0m\t\n",
      "Epoch    39 | LossA: \u001b[91m0.43(+2.27%) ▲\u001b[0m\t| LossAB: \u001b[32m0.19(-65.44%) ▼\u001b[0m\t\n",
      "Epoch    40 | LossA: \u001b[32m0.41(-3.28%) ▼\u001b[0m\t| LossAB: \u001b[91m0.26(+36.93%) ▲\u001b[0m\t\n",
      "Epoch    41 | LossA: \u001b[32m0.39(-4.85%) ▼\u001b[0m\t| LossAB: \u001b[91m0.62(+138.46%) ▲\u001b[0m\t\n",
      "Epoch    42 | LossA: \u001b[32m0.39(-1.25%) ▼\u001b[0m\t| LossAB: \u001b[32m0.32(-48.66%) ▼\u001b[0m\t\n",
      "Epoch    43 | LossA: \u001b[32m0.37(-5.42%) ▼\u001b[0m\t| LossAB: \u001b[91m0.42(+32.91%) ▲\u001b[0m\t\n",
      "Epoch    44 | LossA: \u001b[91m0.37(+0.13%) ▲\u001b[0m\t| LossAB: \u001b[32m0.27(-36.60%) ▼\u001b[0m\t\n",
      "Epoch    45 | LossA: \u001b[91m0.37(+0.64%) ▲\u001b[0m\t| LossAB: \u001b[91m0.37(+38.23%) ▲\u001b[0m\t\n",
      "Epoch    46 | LossA: \u001b[32m0.35(-5.68%) ▼\u001b[0m\t| LossAB: \u001b[91m0.48(+29.30%) ▲\u001b[0m\t\n",
      "Epoch    47 | LossA: \u001b[91m0.39(+13.13%) ▲\u001b[0m\t| LossAB: \u001b[32m0.39(-18.30%) ▼\u001b[0m\t\n",
      "Epoch    48 | LossA: \u001b[32m0.34(-13.55%) ▼\u001b[0m\t| LossAB: \u001b[91m0.57(+45.37%) ▲\u001b[0m\t\n",
      "Epoch    49 | LossA: \u001b[91m0.37(+9.77%) ▲\u001b[0m\t| LossAB: \u001b[32m0.51(-10.01%) ▼\u001b[0m\t\n",
      "Epoch    50 | LossA: \u001b[32m0.31(-15.95%) ▼\u001b[0m\t| LossAB: \u001b[91m0.54(+4.56%) ▲\u001b[0m\t\n",
      "Epoch    51 | LossA: \u001b[91m0.37(+17.99%) ▲\u001b[0m\t| LossAB: \u001b[91m0.62(+14.81%) ▲\u001b[0m\t\n",
      "Epoch    52 | LossA: \u001b[32m0.34(-8.01%) ▼\u001b[0m\t| LossAB: \u001b[91m0.87(+40.70%) ▲\u001b[0m\t\n",
      "Epoch    53 | LossA: \u001b[32m0.31(-9.34%) ▼\u001b[0m\t| LossAB: \u001b[32m0.24(-72.55%) ▼\u001b[0m\t\n",
      "Epoch    54 | LossA: \u001b[91m0.35(+14.00%) ▲\u001b[0m\t| LossAB: \u001b[91m0.62(+159.23%) ▲\u001b[0m\t\n",
      "Epoch    55 | LossA: \u001b[32m0.30(-15.21%) ▼\u001b[0m\t| LossAB: \u001b[91m0.79(+27.81%) ▲\u001b[0m\t\n",
      "Epoch    56 | LossA: \u001b[91m0.34(+14.32%) ▲\u001b[0m\t| LossAB: \u001b[32m0.49(-37.38%) ▼\u001b[0m\t\n",
      "Epoch    57 | LossA: \u001b[32m0.31(-10.18%) ▼\u001b[0m\t| LossAB: \u001b[91m0.59(+19.42%) ▲\u001b[0m\t\n",
      "Epoch    58 | LossA: \u001b[32m0.28(-8.36%) ▼\u001b[0m\t| LossAB: \u001b[32m0.43(-27.88%) ▼\u001b[0m\t\n",
      "300/300 [==============================] - 1s 4ms/step\n",
      "Accuracy: 0.7733333110809326\n"
     ]
    }
   ],
   "source": [
    "y_test_oh = dense_to_one_hot(y_test, num_clases=3)\n",
    "\n",
    "# visualizing losses and accuracy\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "#Observing the losses but can be commented out as it's not mandatory \n",
    "reporter = lossprettifier.LossPrettifier(show_percentage=True)\n",
    "\n",
    "for i in range(numEpochs-1):\n",
    "    reporter(epoch=i, LossA = train_loss[i], LossAB = val_loss[i])\n",
    "\n",
    "# Model evaluation \n",
    "score, acc = model.evaluate(x_test, y_test_oh, batch_size=batch_Size)\n",
    "print(\"Accuracy:\", acc)\n",
    "\n",
    "#if acc>0.675:\n",
    "model.save_weights(modelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.78      0.77       100\n",
      "           1       0.83      0.85      0.84       100\n",
      "           2       0.73      0.69      0.71       100\n",
      "\n",
      "    accuracy                           0.77       300\n",
      "   macro avg       0.77      0.77      0.77       300\n",
      "weighted avg       0.77      0.77      0.77       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_pred = y_pred.reshape(len(y_test), 3)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Writing results on file\n",
    "#f = open(resultPath,'a') #create classification report\n",
    "#f.write(classification_report(y_test, y_pred))\n",
    "#f.write(str(sklm.cohen_kappa_score(y_test, y_pred))+\",\"+str(acc)+\",\"+str(score)+\"\\n\")\n",
    "\n",
    "#f.close()\n",
    "#Print class-wise classification metrics\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.array(['normal', 'COVID19', 'pneumonia']))\n",
    "disp.plot(cmap='Blues') \n",
    "disp.ax_.get_images()[0].set_clim(0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.78      0.77       100\n",
      "           1       0.83      0.85      0.84       100\n",
      "           2       0.73      0.69      0.71       100\n",
      "\n",
      "    accuracy                           0.77       300\n",
      "   macro avg       0.77      0.77      0.77       300\n",
      "weighted avg       0.77      0.77      0.77       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vggModel = VGG19((224,224,3),3, False) #set up model architecture\n",
    "\n",
    "#vggModel.summary()\n",
    "vggModel.load_weights(modelPath) #load weights\n",
    "\n",
    "y_pred = vggModel.predict(x_test)\n",
    "y_pred = y_pred.reshape(len(y_test), 3)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 19524), started 16:28:26 ago. (Use '!kill 19524' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-77b169de5032350f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-77b169de5032350f\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
