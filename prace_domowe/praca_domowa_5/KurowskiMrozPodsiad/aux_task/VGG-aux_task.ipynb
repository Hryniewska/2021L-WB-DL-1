{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kurowskik/data_wb_iad/projekt/DeepCOVIDExplainer/noteboks\n"
     ]
    }
   ],
   "source": [
    "#pip install matplotlib\n",
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "os.chdir(\"/home/kurowskik/data_wb_iad/projekt/DeepCOVIDExplainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('../../data/x_train_undersampled_sh.npy')\n",
    "y_train = np.load('../../data/y_train_undersampled_sh.npy')\n",
    "x_test = np.load('../../data/x_test_undersampled_sh.npy')\n",
    "y_test = np.load('../../data/y_test_undersampled_sh.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5010, 224, 224, 3)\n",
      "(300, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5010,)\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducibility\n",
    "np.random.seed(3768)\n",
    "\n",
    "# use this environment flag to change which GPU to use \n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"  # specify which GPU(s) to be used\n",
    "\n",
    "#Get TensorFlow session\n",
    "def get_session(): \n",
    "    config = tf.ConfigProto() \n",
    "    config.gpu_options.allow_growth = True\n",
    "    return tf.Session(config=config) \n",
    "  \n",
    "# One hot encoding of labels \n",
    "def dense_to_one_hot(labels_dense,num_clases=4):\n",
    "    return np.eye(num_clases)[labels_dense]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kurowskik/data_wb_iad/projekt/DeepCOVIDExplainer\n"
     ]
    }
   ],
   "source": [
    "#x_train /= 255????\n",
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "print( os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/kurowskik/data_wb_iad/projekt/DeepCOVIDExplainer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kurowskik/wbiad3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kurowskik/wbiad3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kurowskik/wbiad3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kurowskik/wbiad3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kurowskik/wbiad3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kurowskik/wbiad3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/kurowskik/wbiad3.6/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kurowskik/wbiad3.6/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kurowskik/wbiad3.6/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kurowskik/wbiad3.6/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kurowskik/wbiad3.6/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kurowskik/wbiad3.6/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import time\n",
    "import csv\n",
    "from PIL import Image\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from keras import initializers\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential,load_model,Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import *\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras import callbacks\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as sklm\n",
    "from utils import lossprettifier\n",
    "from Classifier import VGG\n",
    "from Classifier.VGG import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducibility\n",
    "np.random.seed(3768)\n",
    "\n",
    "# use this environment flag to change which GPU to use \n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"  # specify which GPU(s) to be used\n",
    "\n",
    "#Get TensorFlow session\n",
    "def get_session(): \n",
    "    config = tf.ConfigProto() \n",
    "    config.gpu_options.allow_growth = True\n",
    "    return tf.Session(config=config) \n",
    "  \n",
    "# One hot encoding of labels \n",
    "def dense_to_one_hot(labels_dense,num_clases=4):\n",
    "    return np.eye(num_clases)[labels_dense]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing training and test sets\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = dense_to_one_hot(y_train,num_clases=4)\n",
    "y_valid= dense_to_one_hot(y_valid,num_clases=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kurowskik/wbiad3.6/lib/python3.6/site-packages/keras/preprocessing/image.py:657: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, which overrides setting of `featurewise_center`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    }
   ],
   "source": [
    "#Image data generation for the training \n",
    "datagen = ImageDataGenerator(\n",
    "               featurewise_center = False, \n",
    "               samplewise_center = False,  # set each sample mean to 0\n",
    "               featurewise_std_normalization = True,  \n",
    "               samplewise_std_normalization = False)  \n",
    "\n",
    "datagen.fit(x_train) \n",
    "for i in range(len(x_test)):\n",
    "      x_test[i] = datagen.standardize(x_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createOrRestoreModel(): \n",
    "    vggModel = VGG.VGG19((224,224,3),4, False) #set up model architecture\n",
    "\n",
    "    vggModel.summary()\n",
    "    vggModel.load_weights(\"VGG19_transfer2.h5\") #load weights\n",
    "\n",
    "    model = vggModel\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 2)       56        \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 2)       38        \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 2)       0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 4)       76        \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 4)       148       \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 4)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 8)         296       \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 8)         584       \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 8)         584       \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 8)         584       \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 8)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 16)        1168      \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "Z_4 (Dense)                  (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 487,874\n",
      "Trainable params: 487,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = createOrRestoreModel() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 7.5869 - acc: 0.2578 - val_loss: 8.2038 - val_acc: 0.2255\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 15s 459ms/step - loss: 7.2091 - acc: 0.2676 - val_loss: 8.3003 - val_acc: 0.2275\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 16s 487ms/step - loss: 7.5868 - acc: 0.2510 - val_loss: 8.3325 - val_acc: 0.2275\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 15s 483ms/step - loss: 7.7922 - acc: 0.2353 - val_loss: 8.3325 - val_acc: 0.2275\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 7.4255 - acc: 0.2308 - val_loss: 8.3325 - val_acc: 0.2275\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 17s 525ms/step - loss: 7.6498 - acc: 0.2305 - val_loss: 8.3325 - val_acc: 0.2275\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 14s 426ms/step - loss: 7.3980 - acc: 0.2451 - val_loss: 8.5577 - val_acc: 0.2315\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 13s 391ms/step - loss: 7.4767 - acc: 0.2764 - val_loss: 8.5577 - val_acc: 0.2315\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 12s 382ms/step - loss: 7.5554 - acc: 0.2588 - val_loss: 8.5577 - val_acc: 0.2315\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 12s 379ms/step - loss: 7.6655 - acc: 0.2559 - val_loss: 8.5577 - val_acc: 0.2315\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 13s 407ms/step - loss: 7.7844 - acc: 0.2343 - val_loss: 8.5577 - val_acc: 0.2315\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 14s 449ms/step - loss: 7.6498 - acc: 0.2510 - val_loss: 8.5577 - val_acc: 0.2315\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 14s 430ms/step - loss: 7.3665 - acc: 0.2500 - val_loss: 8.5577 - val_acc: 0.2315\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 16s 487ms/step - loss: 7.5711 - acc: 0.2676 - val_loss: 8.5577 - val_acc: 0.2315\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 12s 368ms/step - loss: 7.9489 - acc: 0.2471 - val_loss: 8.5577 - val_acc: 0.2315\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 12s 364ms/step - loss: 7.3137 - acc: 0.2639 - val_loss: 8.5577 - val_acc: 0.2315\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 13s 412ms/step - loss: 7.9331 - acc: 0.2539 - val_loss: 8.5577 - val_acc: 0.2315\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 13s 394ms/step - loss: 7.5081 - acc: 0.2344 - val_loss: 8.5577 - val_acc: 0.2315\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 13s 399ms/step - loss: 7.4452 - acc: 0.2686 - val_loss: 8.5577 - val_acc: 0.2315\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 12s 369ms/step - loss: 7.9961 - acc: 0.2246 - val_loss: 8.5577 - val_acc: 0.2315\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 12s 381ms/step - loss: 7.4609 - acc: 0.2500 - val_loss: 8.5577 - val_acc: 0.2315\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 7.5120 - acc: 0.2557 - val_loss: 8.5577 - val_acc: 0.2315\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 12s 382ms/step - loss: 7.9489 - acc: 0.2598 - val_loss: 8.5577 - val_acc: 0.2315\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 12s 379ms/step - loss: 7.5891 - acc: 0.2390 - val_loss: 8.5577 - val_acc: 0.2315\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 13s 405ms/step - loss: 7.5081 - acc: 0.2588 - val_loss: 8.5577 - val_acc: 0.2315\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 13s 393ms/step - loss: 7.8859 - acc: 0.2500 - val_loss: 8.5577 - val_acc: 0.2315\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 7.6970 - acc: 0.2373 - val_loss: 8.5577 - val_acc: 0.2315\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 12s 376ms/step - loss: 7.4294 - acc: 0.2480 - val_loss: 8.5577 - val_acc: 0.2315\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 12s 383ms/step - loss: 8.0118 - acc: 0.2549 - val_loss: 8.5577 - val_acc: 0.2315\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 12s 360ms/step - loss: 7.6553 - acc: 0.2427 - val_loss: 8.5577 - val_acc: 0.2315\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 12s 361ms/step - loss: 7.3980 - acc: 0.2656 - val_loss: 8.5577 - val_acc: 0.2315\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 11s 358ms/step - loss: 7.3507 - acc: 0.2383 - val_loss: 8.5577 - val_acc: 0.2315\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 11s 359ms/step - loss: 7.6970 - acc: 0.2422 - val_loss: 8.5577 - val_acc: 0.2315\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 13s 394ms/step - loss: 7.6254 - acc: 0.2671 - val_loss: 8.5577 - val_acc: 0.2315\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 14s 448ms/step - loss: 7.3822 - acc: 0.2500 - val_loss: 8.5577 - val_acc: 0.2315\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 14s 436ms/step - loss: 7.5718 - acc: 0.2566 - val_loss: 8.5577 - val_acc: 0.2315\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 14s 450ms/step - loss: 7.8230 - acc: 0.2432 - val_loss: 8.5255 - val_acc: 0.2295\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 13s 411ms/step - loss: 8.1850 - acc: 0.2627 - val_loss: 8.5899 - val_acc: 0.2295\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 15s 457ms/step - loss: 7.6970 - acc: 0.2529 - val_loss: 8.5899 - val_acc: 0.2295\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 17s 520ms/step - loss: 7.7285 - acc: 0.2344 - val_loss: 8.5899 - val_acc: 0.2295\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 14s 452ms/step - loss: 7.9489 - acc: 0.2510 - val_loss: 8.5899 - val_acc: 0.2295\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 13s 411ms/step - loss: 7.6655 - acc: 0.2520 - val_loss: 8.5899 - val_acc: 0.2295\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 14s 451ms/step - loss: 7.6931 - acc: 0.2470 - val_loss: 8.5899 - val_acc: 0.2295\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 14s 430ms/step - loss: 7.8229 - acc: 0.2705 - val_loss: 8.5899 - val_acc: 0.2295\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 7.1618 - acc: 0.2500 - val_loss: 8.5899 - val_acc: 0.2295\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 13s 394ms/step - loss: 7.7915 - acc: 0.2471 - val_loss: 8.5899 - val_acc: 0.2295\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 13s 395ms/step - loss: 7.7796 - acc: 0.2461 - val_loss: 8.5899 - val_acc: 0.2295\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 12s 372ms/step - loss: 7.6970 - acc: 0.2686 - val_loss: 8.5899 - val_acc: 0.2295\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 12s 380ms/step - loss: 8.0433 - acc: 0.2314 - val_loss: 8.5899 - val_acc: 0.2295\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 16s 492ms/step - loss: 7.4924 - acc: 0.2393 - val_loss: 8.5899 - val_acc: 0.2295\n"
     ]
    }
   ],
   "source": [
    "#Defining hyperparameters\n",
    "batch_Size = 32\n",
    "steps_Per_Epoch = 32\n",
    "numEpochs = 50\n",
    "\n",
    "#Instantating VGG19 model\n",
    "#model = VGG19((224,224,3),4) #VGG19_dense for revised VGG19, VGG19 for VGG19. Please pay attention to VGG16(), chnage the input shape and class number in VGG.py.\n",
    "\n",
    "#Creating an optimizers\n",
    "adaDelta = keras.optimizers.Adadelta(lr=1.0, rho=0.95)\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.95, nesterov=True)\n",
    "model.compile(optimizer = sgd , loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "#Creating early stopping \n",
    "earlystop = EarlyStopping(monitor = 'val_accuracy', min_delta = 0, patience = 50, verbose = 1, mode = 'auto')#, restore_best_weights = True)       \n",
    "\n",
    "train_generator = datagen.flow(x_train, y_train, batch_size = batch_Size)\n",
    "validation_generator = datagen.flow(x_valid, y_valid, batch_size = batch_Size)\n",
    "\n",
    "# Model training\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = steps_Per_Epoch,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = 16,\n",
    "    epochs = numEpochs,\n",
    "    shuffle = True, \n",
    "    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = \"VGG19_transfer_done.h5\"\n",
    "resultPath = 'VGG19_transfer_done.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     0 | LossA: 7.59(+0.00%) \u001b[0m\t| LossAB: 8.20(+0.00%) \u001b[0m\t\n",
      "Epoch     1 | LossA: \u001b[32m7.21(-4.98%) ▼\u001b[0m\t| LossAB: \u001b[91m8.30(+1.18%) ▲\u001b[0m\t\n",
      "Epoch     2 | LossA: \u001b[91m7.59(+5.24%) ▲\u001b[0m\t| LossAB: \u001b[91m8.33(+0.39%) ▲\u001b[0m\t\n",
      "Epoch     3 | LossA: \u001b[91m7.80(+2.79%) ▲\u001b[0m\t| LossAB: \u001b[91m8.33(+0.00%) ▲\u001b[0m\t\n",
      "Epoch     4 | LossA: \u001b[32m7.42(-4.86%) ▼\u001b[0m\t| LossAB: 8.33(+0.00%) \u001b[0m\t\n",
      "Epoch     5 | LossA: \u001b[91m7.65(+3.10%) ▲\u001b[0m\t| LossAB: \u001b[91m8.33(+0.00%) ▲\u001b[0m\t\n",
      "Epoch     6 | LossA: \u001b[32m7.40(-3.29%) ▼\u001b[0m\t| LossAB: \u001b[91m8.56(+2.70%) ▲\u001b[0m\t\n",
      "Epoch     7 | LossA: \u001b[91m7.48(+1.06%) ▲\u001b[0m\t| LossAB: \u001b[32m8.56(-0.00%) ▼\u001b[0m\t\n",
      "Epoch     8 | LossA: \u001b[91m7.56(+1.05%) ▲\u001b[0m\t| LossAB: \u001b[32m8.56(-0.00%) ▼\u001b[0m\t\n",
      "Epoch     9 | LossA: \u001b[91m7.67(+1.46%) ▲\u001b[0m\t| LossAB: 8.56(+0.00%) \u001b[0m\t\n",
      "Epoch    10 | LossA: \u001b[91m7.78(+1.53%) ▲\u001b[0m\t| LossAB: \u001b[91m8.56(+0.00%) ▲\u001b[0m\t\n",
      "Epoch    11 | LossA: \u001b[32m7.65(-1.71%) ▼\u001b[0m\t| LossAB: \u001b[91m8.56(+0.00%) ▲\u001b[0m\t\n",
      "Epoch    12 | LossA: \u001b[32m7.37(-3.70%) ▼\u001b[0m\t| LossAB: \u001b[32m8.56(-0.00%) ▼\u001b[0m\t\n",
      "Epoch    13 | LossA: \u001b[91m7.57(+2.78%) ▲\u001b[0m\t| LossAB: \u001b[32m8.56(-0.00%) ▼\u001b[0m\t\n",
      "Epoch    14 | LossA: \u001b[91m7.95(+4.99%) ▲\u001b[0m\t| LossAB: \u001b[91m8.56(+0.00%) ▲\u001b[0m\t\n",
      "Epoch    15 | LossA: \u001b[32m7.31(-8.05%) ▼\u001b[0m\t| LossAB: \u001b[32m8.56(-0.00%) ▼\u001b[0m\t\n",
      "Epoch    16 | LossA: \u001b[91m7.93(+8.54%) ▲\u001b[0m\t| LossAB: \u001b[91m8.56(+0.00%) ▲\u001b[0m\t\n",
      "Epoch    17 | LossA: \u001b[32m7.51(-5.36%) ▼\u001b[0m\t| LossAB: \u001b[91m8.56(+0.00%) ▲\u001b[0m\t\n",
      "Epoch    18 | LossA: \u001b[32m7.45(-0.84%) ▼\u001b[0m\t| LossAB: \u001b[32m8.56(-0.00%) ▼\u001b[0m\t\n",
      "Epoch    19 | LossA: \u001b[91m8.00(+7.40%) ▲\u001b[0m\t| LossAB: \u001b[32m8.56(-0.00%) ▼\u001b[0m\t\n",
      "Epoch    20 | LossA: \u001b[32m7.46(-6.69%) ▼\u001b[0m\t| LossAB: \u001b[91m8.56(+0.00%) ▲\u001b[0m\t\n",
      "Epoch    21 | LossA: \u001b[91m7.51(+0.72%) ▲\u001b[0m\t| LossAB: 8.56(+0.00%) \u001b[0m\t\n",
      "Epoch    22 | LossA: \u001b[91m7.95(+5.78%) ▲\u001b[0m\t| LossAB: 8.56(+0.00%) \u001b[0m\t\n",
      "Epoch    23 | LossA: \u001b[32m7.59(-4.47%) ▼\u001b[0m\t| LossAB: \u001b[91m8.56(+0.00%) ▲\u001b[0m\t\n",
      "Epoch    24 | LossA: \u001b[32m7.51(-1.12%) ▼\u001b[0m\t| LossAB: \u001b[91m8.56(+0.00%) ▲\u001b[0m\t\n",
      "Epoch    25 | LossA: \u001b[91m7.89(+5.03%) ▲\u001b[0m\t| LossAB: \u001b[32m8.56(-0.00%) ▼\u001b[0m\t\n",
      "Epoch    26 | LossA: \u001b[32m7.70(-2.40%) ▼\u001b[0m\t| LossAB: \u001b[32m8.56(-0.00%) ▼\u001b[0m\t\n",
      "Epoch    27 | LossA: \u001b[32m7.43(-3.48%) ▼\u001b[0m\t| LossAB: \u001b[91m8.56(+0.00%) ▲\u001b[0m\t\n",
      "Epoch    28 | LossA: \u001b[91m8.01(+7.84%) ▲\u001b[0m\t| LossAB: \u001b[32m8.56(-0.00%) ▼\u001b[0m\t\n",
      "Epoch    29 | LossA: \u001b[32m7.66(-4.44%) ▼\u001b[0m\t| LossAB: \u001b[32m8.56(-0.00%) ▼\u001b[0m\t\n",
      "Epoch    30 | LossA: \u001b[32m7.40(-3.38%) ▼\u001b[0m\t| LossAB: \u001b[91m8.56(+0.00%) ▲\u001b[0m\t\n",
      "Epoch    31 | LossA: \u001b[32m7.35(-0.64%) ▼\u001b[0m\t| LossAB: 8.56(+0.00%) \u001b[0m\t\n",
      "Epoch    32 | LossA: \u001b[91m7.70(+4.71%) ▲\u001b[0m\t| LossAB: \u001b[91m8.56(+0.00%) ▲\u001b[0m\t\n",
      "Epoch    33 | LossA: \u001b[32m7.62(-0.94%) ▼\u001b[0m\t| LossAB: \u001b[32m8.56(-0.00%) ▼\u001b[0m\t\n",
      "Epoch    34 | LossA: \u001b[32m7.38(-3.18%) ▼\u001b[0m\t| LossAB: \u001b[91m8.56(+0.00%) ▲\u001b[0m\t\n",
      "Epoch    35 | LossA: \u001b[91m7.58(+2.65%) ▲\u001b[0m\t| LossAB: \u001b[32m8.56(-0.00%) ▼\u001b[0m\t\n",
      "Epoch    36 | LossA: \u001b[91m7.82(+3.24%) ▲\u001b[0m\t| LossAB: \u001b[32m8.53(-0.38%) ▼\u001b[0m\t\n",
      "Epoch    37 | LossA: \u001b[91m8.18(+4.63%) ▲\u001b[0m\t| LossAB: \u001b[91m8.59(+0.75%) ▲\u001b[0m\t\n",
      "Epoch    38 | LossA: \u001b[32m7.70(-5.96%) ▼\u001b[0m\t| LossAB: \u001b[91m8.59(+0.00%) ▲\u001b[0m\t\n",
      "Epoch    39 | LossA: \u001b[91m7.73(+0.41%) ▲\u001b[0m\t| LossAB: 8.59(+0.00%) \u001b[0m\t\n",
      "Epoch    40 | LossA: \u001b[91m7.95(+2.85%) ▲\u001b[0m\t| LossAB: \u001b[32m8.59(-0.00%) ▼\u001b[0m\t\n",
      "Epoch    41 | LossA: \u001b[32m7.67(-3.56%) ▼\u001b[0m\t| LossAB: \u001b[91m8.59(+0.00%) ▲\u001b[0m\t\n",
      "Epoch    42 | LossA: \u001b[91m7.69(+0.29%) ▲\u001b[0m\t| LossAB: \u001b[91m8.59(+0.00%) ▲\u001b[0m\t\n",
      "Epoch    43 | LossA: \u001b[91m7.82(+1.75%) ▲\u001b[0m\t| LossAB: \u001b[91m8.59(+0.00%) ▲\u001b[0m\t\n",
      "Epoch    44 | LossA: \u001b[32m7.16(-8.45%) ▼\u001b[0m\t| LossAB: \u001b[32m8.59(-0.00%) ▼\u001b[0m\t\n",
      "Epoch    45 | LossA: \u001b[91m7.79(+8.79%) ▲\u001b[0m\t| LossAB: \u001b[91m8.59(+0.00%) ▲\u001b[0m\t\n",
      "Epoch    46 | LossA: \u001b[32m7.78(-0.11%) ▼\u001b[0m\t| LossAB: 8.59(+0.00%) \u001b[0m\t\n",
      "Epoch    47 | LossA: \u001b[32m7.70(-1.10%) ▼\u001b[0m\t| LossAB: \u001b[91m8.59(+0.00%) ▲\u001b[0m\t\n",
      "Epoch    48 | LossA: \u001b[91m8.04(+4.50%) ▲\u001b[0m\t| LossAB: \u001b[32m8.59(-0.00%) ▼\u001b[0m\t\n",
      "300/300 [==============================] - 1s 4ms/step\n",
      "Accuracy: 0.24666666666666667\n"
     ]
    }
   ],
   "source": [
    "y_test_oh = dense_to_one_hot(y_test, num_clases=4)\n",
    "\n",
    "# visualizing losses and accuracy\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "#Observing the losses but can be commented out as it's not mandatory \n",
    "reporter = lossprettifier.LossPrettifier(show_percentage=True)\n",
    "\n",
    "for i in range(numEpochs-1):\n",
    "    reporter(epoch=i, LossA = train_loss[i], LossAB = val_loss[i])\n",
    "\n",
    "# Model evaluation \n",
    "#score, acc = model.evaluate(x_test, y_test_oh, batch_size=batch_Size)\n",
    "score, acc = model.evaluate(x_test, y_test_oh, batch_size=batch_Size)\n",
    "print(\"Accuracy:\", acc)\n",
    "\n",
    "#if acc>0.675:\n",
    "model.save_weights(modelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.64      0.39       100\n",
      "           1       0.14      0.10      0.12       100\n",
      "           2       0.00      0.00      0.00       100\n",
      "\n",
      "    accuracy                           0.25       300\n",
      "   macro avg       0.14      0.25      0.17       300\n",
      "weighted avg       0.14      0.25      0.17       300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kurowskik/wbiad3.6/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_pred = y_pred.reshape(len(y_test), 4)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Writing results on file\n",
    "f = open(resultPath,'a') #create classification report\n",
    "f.write(classification_report(y_test, y_pred))\n",
    "f.write(str(sklm.cohen_kappa_score(y_test, y_pred))+\",\"+str(acc)+\",\"+str(score)+\"\\n\")\n",
    "\n",
    "#Print class-wise classification metrics\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 2)       56        \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 2)       38        \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 2)       0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 4)       76        \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 4)       148       \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 4)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 8)         296       \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 8)         584       \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 8)         584       \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 8)         584       \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 8)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 16)        1168      \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 487,874\n",
      "Trainable params: 487,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.array(['normal', 'COVID19', 'pneumonia']))\n",
    "disp.plot(cmap='Blues') \n",
    "disp.ax_.get_images()[0].set_clim(0, 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wbiad3.6",
   "language": "python",
   "name": "wbiad3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
